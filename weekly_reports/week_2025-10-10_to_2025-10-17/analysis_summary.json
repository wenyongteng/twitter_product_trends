{
  "summary": {
    "total_tweets": 2038,
    "unique_products": 643,
    "new_products": 121,
    "top_topics": {
      "AI": 742,
      "model": 150,
      "agent": 110,
      "AGI": 59,
      "coding": 39,
      "LLM": 37,
      "design": 35,
      "ML": 30,
      "startup": 14,
      "development": 12
    },
    "date_range": {
      "start": "2025-10-10",
      "end": "2025-10-17"
    }
  },
  "products": {
    "Claude": {
      "mention_count": 77,
      "top_kols": [
        "ArtificialAnlys",
        "ArtificialAnlys",
        "ArtificialAnlys",
        "ArtificialAnlys",
        "ArtificialAnlys"
      ],
      "sentiment": {
        "neutral": 67,
        "positive": 10
      },
      "total_engagement": 18812,
      "sample_tweets": [
        {
          "text": "Claude Haiku 4.5, rolling out to @code today\n\nLearn more: https://t.co/D8ghyOLgd0 https://t.co/s56SNBoTMn",
          "kol": "code",
          "rank": 4,
          "followers": 770831,
          "likes": 909,
          "retweets": 102,
          "created_at": "Wed Oct 15 19:04:52 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "Compare Claude 4.5 Haiku to other models on Artificial Analysis:\n\nhttps://t.co/pWxqQBYac9",
          "kol": "ArtificialAnlys",
          "rank": 20,
          "followers": 60488,
          "likes": 11,
          "retweets": 0,
          "created_at": "Thu Oct 16 03:17:59 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "Claude 4.5 Haiku is on the frontier for Anthropic models when looking at the trade-off between intelligence and cost to run the Artificial Analysis Intelligence Index. This makes Claude 4.5 Haiku a valid alternative to Claude 4.5 Sonnet for users who want to access ‚ÄòClaude‚Äô at a cheaper price point",
          "kol": "ArtificialAnlys",
          "rank": 20,
          "followers": 60488,
          "likes": 11,
          "retweets": 1,
          "created_at": "Thu Oct 16 03:17:57 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        }
      ]
    },
    "OpenAI": {
      "mention_count": 74,
      "top_kols": [
        "DotCSV",
        "DotCSV",
        "ai_for_success",
        "ai_for_success",
        "kimmonismus"
      ],
      "sentiment": {
        "neutral": 68,
        "negative": 1,
        "positive": 5
      },
      "total_engagement": 12987,
      "sample_tweets": [
        {
          "text": "En este v√≠deo os ense√±ar√© y comparamos:\n\n‚ñ∑ OpenAI Agent Builder\n‚ñ∑ Google Opal\n‚ñ∑ N8N\n\nTres herramientas de automatizaci√≥n que debes de conocer!\n\nhttps://t.co/nr7V9jnhKK",
          "kol": "DotCSV",
          "rank": 1,
          "followers": 195063,
          "likes": 58,
          "retweets": 7,
          "created_at": "Sun Oct 12 17:01:47 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "üî•üî• ¬°NUEVO V√çDEO en el LAB! üî•üî•\n\nEsta semana OpenAI present√≥ su nueva herramienta de creaci√≥n de AGENTES (...workflows) y muchos dieron por muerta a herramientas como n8n.\n\nLa realidad es otra y hoy te ense√±o 3 HERRAMIENTAS s√∫per √∫tiles para que empieces a automatizarlo TODO!",
          "kol": "DotCSV",
          "rank": 1,
          "followers": 195063,
          "likes": 502,
          "retweets": 54,
          "created_at": "Sun Oct 12 16:58:41 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "Per Brad Gerstner (investor in OpenAI): OpenAI is release GPT-6 before end of the year! So in the next 1.5 months we will see another big release! https://t.co/DcYXW1iRY0",
          "kol": "kimmonismus",
          "rank": 3,
          "followers": 86148,
          "likes": 140,
          "retweets": 10,
          "created_at": "Fri Oct 17 08:14:20 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        }
      ]
    },
    "Gemini": {
      "mention_count": 52,
      "top_kols": [
        "ArtificialAnlys",
        "ArtificialAnlys",
        "ai_for_success",
        "ai_for_success",
        "scaling01"
      ],
      "sentiment": {
        "neutral": 49,
        "positive": 3
      },
      "total_engagement": 10422,
      "sample_tweets": [
        {
          "text": "Google Gemini website hinting at Gemini 3.0 Pro\n\"our smartest model yet\" https://t.co/s7ypxTldeY",
          "kol": "scaling01",
          "rank": 8,
          "followers": 22096,
          "likes": 666,
          "retweets": 20,
          "created_at": "Wed Oct 15 19:49:02 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "üö® Google has rolled out a new unified playground experience in AI Studio, combining Chat, GenMedia, and Live in a single interface.  \n\nAll set for Gemini 3.0? What do you think?\nhttps://t.co/LoUcKsdGEG",
          "kol": "ai_for_success",
          "rank": 9,
          "followers": 67813,
          "likes": 179,
          "retweets": 15,
          "created_at": "Thu Oct 16 16:49:42 +0000 2025",
          "sentiment": "neutral",
          "is_new": true
        },
        {
          "text": "When you see Gemini 3.0 Pro. https://t.co/CIJjaIIezG",
          "kol": "ai_for_success",
          "rank": 9,
          "followers": 67813,
          "likes": 831,
          "retweets": 35,
          "created_at": "Thu Oct 16 16:00:45 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        }
      ]
    },
    "ChatGPT": {
      "mention_count": 35,
      "top_kols": [
        "karpathy",
        "scaling01"
      ],
      "sentiment": {
        "neutral": 30,
        "positive": 5
      },
      "total_engagement": 13983,
      "sample_tweets": [
        {
          "text": "nanochat d32, i.e. the depth 32 version that I specced for $1000, up from $100 has finished training after ~33 hours, and looks good. All the metrics go up quite a bit across pretraining, SFT and RL. CORE score of 0.31 is now well above GPT-2 at ~0.26. GSM8K went ~8% -> ~20%, etc. So that's encouraging.\n\nThe model is pretty fun to talk to, but judging from some early interactions I think people have a little bit too much expectation for these micro models. There is a reason that frontier LLM labs raise billions to train their models. nanochat models cost $100 - $1000 to train from scratch. The $100 nanochat is 1/1000th the size of GPT-3 in parameters, which came out 5 years ago. So I urge some perspective. Talking to micro models you have to imagine you're talking to a kindergarten child. They say cute things, wrong things, they are a bit confused, a bit naive, sometimes a little non-sensical, they hallucinate a ton (but it's amusing), etc.\n\nFull detail/report on this run is here:\nhttps://t.co/nWbfKOZLIg\nAnd I pushed the new script run1000 sh to the nanochat repo if anyone would like to reproduce. Totally understand if you'd like to spend $1000 on something else :D\n\nIf you like, I am currently hosting the model so you can talk to it on a webchat as you'd talk to ChatGPT. I'm not going to post the URL here because I'm afraid it will get crushed. You'll have to look for it if you care enough. I'm also attaching a few funny conversations I had with the model earlier into the image, just to give a sense.\n\nNext up, I am going to do one pass of tuning and optimizing the training throughput, then maybe return back to scaling and maybe training the next tier of a bigger model.",
          "kol": "karpathy",
          "rank": 7,
          "followers": 1405116,
          "likes": 3426,
          "retweets": 320,
          "created_at": "Thu Oct 16 00:14:42 +0000 2025",
          "sentiment": "neutral",
          "is_new": true
        },
        {
          "text": "Shit's going to be real fun in 5 years when ChatGPT is no longer growing and it becomes just another despicable subscription service like Netflix. They will start raising prices and monetize everything they can. (for all of humanity ofc)",
          "kol": "scaling01",
          "rank": 8,
          "followers": 22096,
          "likes": 139,
          "retweets": 4,
          "created_at": "Thu Oct 16 10:10:40 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "‚ÄúChatGPT-6 is coming out before the end of the year‚Äù",
          "kol": "btibor91",
          "rank": 25,
          "followers": 31609,
          "likes": 738,
          "retweets": 62,
          "created_at": "Thu Oct 16 20:58:20 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        }
      ]
    },
    "Anthropic": {
      "mention_count": 25,
      "top_kols": [
        "ArtificialAnlys",
        "ArtificialAnlys",
        "ArtificialAnlys",
        "scaling01",
        "testingcatalog"
      ],
      "sentiment": {
        "neutral": 25
      },
      "total_engagement": 2614,
      "sample_tweets": [
        {
          "text": "Not a good metric. We already know that GPT-5 codex needs more actions / tools calls than Anthropic models",
          "kol": "scaling01",
          "rank": 8,
          "followers": 22096,
          "likes": 82,
          "retweets": 2,
          "created_at": "Thu Oct 16 00:43:58 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "Anthropic released Microsoft 365 Connectors and Enterprise Search for Team and Enterprise accounts. https://t.co/jcMJG77oXc",
          "kol": "testingcatalog",
          "rank": 19,
          "followers": 34948,
          "likes": 130,
          "retweets": 11,
          "created_at": "Thu Oct 16 16:48:04 +0000 2025",
          "sentiment": "neutral",
          "is_new": true
        },
        {
          "text": "Claude 4.5 Haiku is on the frontier for Anthropic models when looking at the trade-off between intelligence and cost to run the Artificial Analysis Intelligence Index. This makes Claude 4.5 Haiku a valid alternative to Claude 4.5 Sonnet for users who want to access ‚ÄòClaude‚Äô at a cheaper price point",
          "kol": "ArtificialAnlys",
          "rank": 20,
          "followers": 60488,
          "likes": 11,
          "retweets": 1,
          "created_at": "Thu Oct 16 03:17:57 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        }
      ]
    },
    "GPT-5": {
      "mention_count": 21,
      "top_kols": [
        "ArtificialAnlys",
        "ArtificialAnlys",
        "scaling01",
        "slow_developer"
      ],
      "sentiment": {
        "neutral": 19,
        "positive": 2
      },
      "total_engagement": 4205,
      "sample_tweets": [
        {
          "text": "we finally know how close we are to AGI\n\nthe paper tested the GPT-4 and GPT-5 on human cognitive abilities:\n\n> GPT-5 scored 58% toward AGI\n> GPT-4 scored 27%\n\nthe research also shows \"jagged intelligence\", which helps explain why AI can feel both very impressive and surprisingly weak at the same time",
          "kol": "slow_developer",
          "rank": 5,
          "followers": 51148,
          "likes": 397,
          "retweets": 60,
          "created_at": "Fri Oct 17 00:10:00 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "Not a good metric. We already know that GPT-5 codex needs more actions / tools calls than Anthropic models",
          "kol": "scaling01",
          "rank": 8,
          "followers": 22096,
          "likes": 82,
          "retweets": 2,
          "created_at": "Thu Oct 16 00:43:58 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "Anthropic launches their first Haiku model in 11 months - Claude 4.5 Haiku jumps 35 points in Artificial Analysis Intelligence Index to become relevant again\n\nClaude 4.5 Haiku is 3x cheaper per token than Claude 4.5 Sonnet. Running the Artificial Analysis Intelligence Index costs $262 with Haiku vs. $817 with Sonnet (~3x more) - full cost breakdown in the thread below.\n\nThere is a stronger case for 4.5 Haiku‚Äôs intelligence/cost positioning than 3.5 Haiku, but there is a competitive field of cheaper alternatives with similar intelligence that may make more sense for developers without a reason to need a Claude model specifically - including gpt-oss-120b (reasoning high, ~$75) and Grok 4 Fast (~$40). Claude 4.5 Haiku is the most cost-effective way to access ‚ÄòClaude‚Äô but is not the most cost effective model for its level of intelligence.\n\nKey benchmarking results:\n‚û§üß† Model Intelligence: In reasoning mode, Claude 4.5 Haiku scores 55 on the Artificial Analysis Intelligence Index. This is 8 points lower than Claude 4.5 Sonnet (Thinking) and 4 points lower than Claude 4.1 Opus (Thinking). Claude 4.5 Haiku (Thinking) places marginally ahead of Gemini 2.5 Flash (Reasoning, 54) but behind other reasoning models such as Qwen3 235B 2507 (57), DeepSeek V3.2 Exp (57), and GLM 4.6 (56)\n‚û§üìà Intelligence Uplift: Anthropic released Claude 3.5 Haiku in November 2024, ~11 months before the release of Claude 4.5 Haiku. Claude 4.5 Haiku is a significant improvement in intelligence compared to Claude 3.5 Haiku, scoring 67% on GPQA Diamond in reasoning mode (compared to 41% for Claude 3.5 Haiku)\n‚û§‚öôÔ∏è Notable Strengths: In reasonign mode, Claude 4.5 Haiku performs well in long-context reasoning (70% on AA-LCR, behind only GPT-5 High) and coding (43%, matching GPT-5 High and Gemini 2.5 Pro)\n‚û§‚ö° Non-Reasoning Performance: In non-reasoning mode, Claude 4.5 Haiku scores 42 on the Artificial Analysis Intelligence Index. This places the model in line with GPT-5 (minimal, 43) but behind Gemini 2.5 Flash (non-reasoning, 47)\n‚û§üí≤ Pricing: Claude 4.5 Haiku is priced at $1/$5 per 1M input/output tokens, which makes it 3x cheaper compared to Claude 4.5 Sonnet (priced at $3/$15 per 1M input/output tokens)\n‚û§‚öôÔ∏è Token Efficiency: Anthropic‚Äôs Claude models continue to be more token-efficient than all other reasoning models. For Claude 4.5 Haiku (Thinking) -evaluated with a maximum reasoning budget of 64k tokens - we see the model use 39M output tokens to run the Artificial Analysis Intelligence Index. Its token usage is lower than Claude 4.5 Sonnet (42M) but higher than Claude 4.1 Opus (30M) in thinking mode\n\nKey model details:\n\n‚û§üìè¬†Context Window: 200K tokens. This is equivalent to Claude 4.5 Sonnet\n‚û§üåê¬†Availability: Claude 4.5 Haiku is available via Anthropic‚Äòs API, Google Vertex and Amazon Bedrock. Claude 4.5 Haiku is also available via Claude, and Claude Code",
          "kol": "ArtificialAnlys",
          "rank": 20,
          "followers": 60488,
          "likes": 352,
          "retweets": 37,
          "created_at": "Thu Oct 16 03:17:55 +0000 2025",
          "sentiment": "neutral",
          "is_new": true
        }
      ]
    },
    "Copilot": {
      "mention_count": 17,
      "top_kols": [
        "satyanadella",
        "satyanadella",
        "satyanadella"
      ],
      "sentiment": {
        "neutral": 15,
        "positive": 1,
        "negative": 1
      },
      "total_engagement": 5839,
      "sample_tweets": [
        {
          "text": "Hey Copilot! Show everyone how we‚Äôre transforming how you interact with your Windows PC ‚Äî so you can talk naturally, it can see what you see, and take action on your behalf. https://t.co/1YF1zK8Uj0",
          "kol": "satyanadella",
          "rank": 18,
          "followers": 3494385,
          "likes": 1699,
          "retweets": 227,
          "created_at": "Thu Oct 16 13:08:24 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "This is super useful! With new Formula Completions in Excel, just type \"=\" and Copilot proactively suggests a formula, based on the context of your sheet. Here's a great example. https://t.co/elkGzHjZTW",
          "kol": "satyanadella",
          "rank": 18,
          "followers": 3494385,
          "likes": 2130,
          "retweets": 302,
          "created_at": "Tue Oct 14 19:03:08 +0000 2025",
          "sentiment": "positive",
          "is_new": true
        },
        {
          "text": "These are all live today! Just go to the Agent Store in Copilot to try them out, along with dozens of others.\nLearn more: https://t.co/CTij41cg19",
          "kol": "satyanadella",
          "rank": 18,
          "followers": 3494385,
          "likes": 154,
          "retweets": 20,
          "created_at": "Sun Oct 12 20:57:51 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        }
      ]
    },
    "claude": {
      "mention_count": 14,
      "top_kols": [
        "karpathy"
      ],
      "sentiment": {
        "neutral": 14
      },
      "total_engagement": 6181,
      "sample_tweets": [
        {
          "text": "@zenitsu_aprntc Good question, it's basically entirely hand-written (with tab autocomplete). I tried to use claude/codex agents a few times but they just didn't work well enough at all and net unhelpful, possibly the repo is too far off the data distribution.",
          "kol": "karpathy",
          "rank": 7,
          "followers": 1405116,
          "likes": 1504,
          "retweets": 102,
          "created_at": "Mon Oct 13 15:27:55 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "(4/n) „ÄêÂà©Áî®ÊñπÊ≥ï„ÉªÂØæË±°„É¶„Éº„Ç∂„Éº„Äë\n\nüì± https://t.co/Ph3Yd8Q9hkÔºàPro/Max/Team/EnterpriseÔºâ\nË®≠ÂÆö„Åã„ÇâÊúâÂäπÂåñ‚ÜíËá™ÂãïËµ∑Âãï\n\nüíª APIÈñãÁô∫ËÄÖ\nMessages API + /v1/skills „Ç®„É≥„Éâ„Éù„Ç§„É≥„Éà\nCode Execution Tool (beta) „ÅåÂøÖË¶Å\n\n‚öôÔ∏è Claude Code\n„Éó„É©„Ç∞„Ç§„É≥„Åã„Çâ„Ç§„É≥„Çπ„Éà„Éº„É´\n~/.claude/skills „Å´ÊâãÂãïÈÖçÁΩÆ„ÇÇÂèØ https://t.co/TzsZelT38M",
          "kol": "masahirochaen",
          "rank": 50,
          "followers": 172150,
          "likes": 23,
          "retweets": 0,
          "created_at": "Thu Oct 16 22:02:12 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "Or go try out Skills in claude dot ai: https://t.co/W5GdkvlVKL",
          "kol": "alexalbert__",
          "rank": 61,
          "followers": 99437,
          "likes": 54,
          "retweets": 5,
          "created_at": "Thu Oct 16 17:36:05 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        }
      ]
    },
    "GoogleAIStudio": {
      "mention_count": 14,
      "top_kols": [
        "testingcatalog"
      ],
      "sentiment": {
        "neutral": 14
      },
      "total_engagement": 983,
      "sample_tweets": [
        {
          "text": "@OfficialLoganK @GoogleAIStudio Aaaand a working model selector in the build section üî•",
          "kol": "testingcatalog",
          "rank": 19,
          "followers": 34948,
          "likes": 40,
          "retweets": 0,
          "created_at": "Thu Oct 16 16:42:37 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "@OfficialLoganK @GoogleAIStudio Logan can we get to know if Gemini Gemini Gemini is coming this month?",
          "kol": "Angaisb_",
          "rank": 24,
          "followers": 5505,
          "likes": 45,
          "retweets": 0,
          "created_at": "Thu Oct 16 16:37:44 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "@alex_barashkov @GoogleAIStudio we are fixing this, a totally new billing experience will land in Jan :) long long time coming",
          "kol": "OfficialLoganK",
          "rank": 33,
          "followers": 216323,
          "likes": 19,
          "retweets": 0,
          "created_at": "Thu Oct 16 18:56:03 +0000 2025",
          "sentiment": "neutral",
          "is_new": true
        }
      ]
    },
    "GPT-6": {
      "mention_count": 12,
      "top_kols": [
        "ai_for_success",
        "kimmonismus",
        "slow_developer",
        "testingcatalog"
      ],
      "sentiment": {
        "neutral": 11,
        "positive": 1
      },
      "total_engagement": 1261,
      "sample_tweets": [
        {
          "text": "Per Brad Gerstner (investor in OpenAI): OpenAI is release GPT-6 before end of the year! So in the next 1.5 months we will see another big release! https://t.co/DcYXW1iRY0",
          "kol": "kimmonismus",
          "rank": 3,
          "followers": 86148,
          "likes": 140,
          "retweets": 10,
          "created_at": "Fri Oct 17 08:14:20 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "GPT-6 before GTA-6\n\nit would be something no one expects right now.\n\nand surely the AI bubble isn't ready for what's coming",
          "kol": "slow_developer",
          "rank": 5,
          "followers": 51148,
          "likes": 59,
          "retweets": 1,
          "created_at": "Fri Oct 17 07:35:33 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "GPT-6 by end of this year as per CNBC.\nhttps://t.co/PcrO0nP829",
          "kol": "ai_for_success",
          "rank": 9,
          "followers": 67813,
          "likes": 25,
          "retweets": 3,
          "created_at": "Fri Oct 17 00:37:49 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        }
      ]
    },
    "Grok": {
      "mention_count": 11,
      "top_kols": [
        "Artedeingenio",
        "ArtificialAnlys"
      ],
      "sentiment": {
        "neutral": 8,
        "positive": 2,
        "negative": 1
      },
      "total_engagement": 1701,
      "sample_tweets": [
        {
          "text": "Anna Karenina in 80s OVA-style anime is something so beautiful and poetic üöÇ‚ùÑÔ∏è\n\nAnd it‚Äôs all thanks to Grok Imagine. https://t.co/bv0Zm2Tbpn",
          "kol": "Artedeingenio",
          "rank": 2,
          "followers": 38294,
          "likes": 7,
          "retweets": 0,
          "created_at": "Fri Oct 17 11:26:31 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "Anthropic launches their first Haiku model in 11 months - Claude 4.5 Haiku jumps 35 points in Artificial Analysis Intelligence Index to become relevant again\n\nClaude 4.5 Haiku is 3x cheaper per token than Claude 4.5 Sonnet. Running the Artificial Analysis Intelligence Index costs $262 with Haiku vs. $817 with Sonnet (~3x more) - full cost breakdown in the thread below.\n\nThere is a stronger case for 4.5 Haiku‚Äôs intelligence/cost positioning than 3.5 Haiku, but there is a competitive field of cheaper alternatives with similar intelligence that may make more sense for developers without a reason to need a Claude model specifically - including gpt-oss-120b (reasoning high, ~$75) and Grok 4 Fast (~$40). Claude 4.5 Haiku is the most cost-effective way to access ‚ÄòClaude‚Äô but is not the most cost effective model for its level of intelligence.\n\nKey benchmarking results:\n‚û§üß† Model Intelligence: In reasoning mode, Claude 4.5 Haiku scores 55 on the Artificial Analysis Intelligence Index. This is 8 points lower than Claude 4.5 Sonnet (Thinking) and 4 points lower than Claude 4.1 Opus (Thinking). Claude 4.5 Haiku (Thinking) places marginally ahead of Gemini 2.5 Flash (Reasoning, 54) but behind other reasoning models such as Qwen3 235B 2507 (57), DeepSeek V3.2 Exp (57), and GLM 4.6 (56)\n‚û§üìà Intelligence Uplift: Anthropic released Claude 3.5 Haiku in November 2024, ~11 months before the release of Claude 4.5 Haiku. Claude 4.5 Haiku is a significant improvement in intelligence compared to Claude 3.5 Haiku, scoring 67% on GPQA Diamond in reasoning mode (compared to 41% for Claude 3.5 Haiku)\n‚û§‚öôÔ∏è Notable Strengths: In reasonign mode, Claude 4.5 Haiku performs well in long-context reasoning (70% on AA-LCR, behind only GPT-5 High) and coding (43%, matching GPT-5 High and Gemini 2.5 Pro)\n‚û§‚ö° Non-Reasoning Performance: In non-reasoning mode, Claude 4.5 Haiku scores 42 on the Artificial Analysis Intelligence Index. This places the model in line with GPT-5 (minimal, 43) but behind Gemini 2.5 Flash (non-reasoning, 47)\n‚û§üí≤ Pricing: Claude 4.5 Haiku is priced at $1/$5 per 1M input/output tokens, which makes it 3x cheaper compared to Claude 4.5 Sonnet (priced at $3/$15 per 1M input/output tokens)\n‚û§‚öôÔ∏è Token Efficiency: Anthropic‚Äôs Claude models continue to be more token-efficient than all other reasoning models. For Claude 4.5 Haiku (Thinking) -evaluated with a maximum reasoning budget of 64k tokens - we see the model use 39M output tokens to run the Artificial Analysis Intelligence Index. Its token usage is lower than Claude 4.5 Sonnet (42M) but higher than Claude 4.1 Opus (30M) in thinking mode\n\nKey model details:\n\n‚û§üìè¬†Context Window: 200K tokens. This is equivalent to Claude 4.5 Sonnet\n‚û§üåê¬†Availability: Claude 4.5 Haiku is available via Anthropic‚Äòs API, Google Vertex and Amazon Bedrock. Claude 4.5 Haiku is also available via Claude, and Claude Code",
          "kol": "ArtificialAnlys",
          "rank": 20,
          "followers": 60488,
          "likes": 352,
          "retweets": 37,
          "created_at": "Thu Oct 16 03:17:55 +0000 2025",
          "sentiment": "neutral",
          "is_new": true
        },
        {
          "text": "Ani won.\nGrok won. https://t.co/XrLBlhFAR3",
          "kol": "ns123abc",
          "rank": 75,
          "followers": 43155,
          "likes": 49,
          "retweets": 1,
          "created_at": "Fri Oct 17 07:49:45 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        }
      ]
    },
    "Cursor": {
      "mention_count": 11,
      "top_kols": [],
      "sentiment": {
        "neutral": 10,
        "positive": 1
      },
      "total_engagement": 527,
      "sample_tweets": [
        {
          "text": "Cursor Meetup Osaka „ÅÆ„É¢„Éé„Çø„É≠„Ç¶„Åï„Çì„ÅÆÁô∫Ë°®„ÇÇ„ÄÅÊÑèÂ§ñ„Å™„Åì„Å®„Å´Ôºü„ÄÅIDE „Çà„Çä„ÇÇ Devin „ÅÆÊñπ„ÅåÂäπÊûúÔºàPRÊï∞Ôºâ„ÅåÊòé„Çâ„Åã„Åß„Åó„Åü„ÄÇÈùûÂ∏∏„Å´ËààÂë≥Ê∑±„ÅÑÁÇπ„Åß„Åô„ÄÇ https://t.co/1tbGYMkCIz",
          "kol": "kinopee_ai",
          "rank": 86,
          "followers": 12209,
          "likes": 10,
          "retweets": 1,
          "created_at": "Fri Oct 17 08:41:48 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "Cursor Agent Review„ÄÅCodeRabbit „Åß„ÇÇÊ§úÂá∫0„ÅÆ„Éñ„É©„É≥„ÉÅ„Åß4‰ª∂ÂïèÈ°åÊ§úÂá∫„ÄÇ„Åü„Å†„Åó„ÄÅ„Åì„ÅÆÂÜÖÂÆπ„Çí GPT-5-Codex „Å´Á¢∫Ë™ç„Åï„Åõ„Åü„Çâ„ÄÅÂØæÂøú„ÅÆÂøÖË¶Å„ÅØ„Å™„Åó„ÄÇ\n„ÉÑ„Éº„É´„Åî„Å®„Å´Â∑ÆÁï∞„Åå„ÅÇ„Çã„ÅÆ„ÅØ„ÅÑ„Å§„ÇÇ„ÅÆ„Åì„Å®„Å†„Åë„Å©„ÄÅ‰ªäÂõû„ÅØÂ∞ë„Åó„Éñ„É¨ÂπÖ„ÅåÂ§ß„Åç„ÅÑÊ∞ó„Åå„Åô„Çã„ÄÇ https://t.co/3strZudx2G",
          "kol": "kinopee_ai",
          "rank": 86,
          "followers": 12209,
          "likes": 7,
          "retweets": 0,
          "created_at": "Fri Oct 17 07:19:54 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "In terms of Cursor extensions and MCP tools, I use two:\n\n- Context 7, which pulls in documentation for libraries\n- Perplexity's MCP server (much better than Cursors built-in search. )\n\nDocs here: https://t.co/ELxRjy0xc5",
          "kol": "maccaw",
          "rank": 97,
          "followers": 39332,
          "likes": 7,
          "retweets": 0,
          "created_at": "Thu Oct 16 17:20:30 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        }
      ]
    },
    "VS Code": {
      "mention_count": 9,
      "top_kols": [
        "code",
        "code",
        "code",
        "code",
        "code"
      ],
      "sentiment": {
        "neutral": 7,
        "positive": 2
      },
      "total_engagement": 803,
      "sample_tweets": [
        {
          "text": "#TBT to the VS Code Dev Days across North America! üåé\n\nFrom coast to coast, local communities in the United States and Canada hosted 16 events packed with inspiring talks and hands-on coding sessions, bringing developers together to learn, build, and connect. \n\nSpecial thanks to @ProgressSW for supporting events in Boston, Chicago, Raleigh and Tulsa! üíª‚ö°\n\nHere‚Äôs a look at some of those moments üëá",
          "kol": "code",
          "rank": 4,
          "followers": 770831,
          "likes": 29,
          "retweets": 4,
          "created_at": "Thu Oct 16 22:05:07 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "@ProgressSW In Peru, local communities hosted 3 VS Code Dev Days in Lima, featuring talks and hands-on sessions for developers to learn and practice new skills. üíª‚ú® https://t.co/XcWsLhX25Q",
          "kol": "code",
          "rank": 4,
          "followers": 770831,
          "likes": 13,
          "retweets": 0,
          "created_at": "Thu Oct 16 18:15:32 +0000 2025",
          "sentiment": "neutral",
          "is_new": true
        },
        {
          "text": "@ProgressSW Next stop: Mexico! ‚ö°\n\nVS Code Dev Days brought developers together in Monterrey, Tuxtla Guti√©rrez, and Mexico City, sharing knowledge, building projects, and connecting as a community üíô https://t.co/F7eSprTeNJ",
          "kol": "code",
          "rank": 4,
          "followers": 770831,
          "likes": 5,
          "retweets": 0,
          "created_at": "Thu Oct 16 18:15:32 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        }
      ]
    },
    "gemini": {
      "mention_count": 9,
      "top_kols": [],
      "sentiment": {
        "positive": 1,
        "neutral": 7,
        "negative": 1
      },
      "total_engagement": 1803,
      "sample_tweets": [
        {
          "text": "gemini 3 pro just created this incredible svg painting guys https://t.co/tXqsjnEzmv",
          "kol": "adonis_singh",
          "rank": 55,
          "followers": 13976,
          "likes": 385,
          "retweets": 8,
          "created_at": "Tue Oct 14 23:53:16 +0000 2025",
          "sentiment": "positive",
          "is_new": false
        },
        {
          "text": "gemini 3 got me o3 levels of excited",
          "kol": "adonis_singh",
          "rank": 55,
          "followers": 13976,
          "likes": 500,
          "retweets": 15,
          "created_at": "Tue Oct 14 21:16:26 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "we somehow have more demos of gemini 3 before it's release than we ever did for 2.5 pro",
          "kol": "adonis_singh",
          "rank": 55,
          "followers": 13976,
          "likes": 406,
          "retweets": 5,
          "created_at": "Tue Oct 14 15:54:25 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        }
      ]
    },
    "launched": {
      "mention_count": 9,
      "top_kols": [],
      "sentiment": {
        "neutral": 8,
        "positive": 1
      },
      "total_engagement": 1431,
      "sample_tweets": [
        {
          "text": "Axios broke this a few minutes ago. This is the first person to join the OpenAI for Science initiative launched by Kevin Weil.",
          "kol": "AndrewCurran_",
          "rank": 84,
          "followers": 34611,
          "likes": 288,
          "retweets": 10,
          "created_at": "Thu Oct 16 14:12:48 +0000 2025",
          "sentiment": "neutral",
          "is_new": true
        },
        {
          "text": "BOOM: We've just re-launched HuggingChat v2 üí¨ - 115 open source models in a single interface is stronger than ChatGPT üî•\n\nIntroducing: HuggingChat Omni üí´\n> Select the best model for every prompt automatically üöÄ\n> Automatic model selection for your queries\n> 115 models available across 15 providers including @GroqInc, @CerebrasSystems, @togethercompute, @novita_labs, and more\n\nPowered by HF Inference Providers ‚Äî access hundreds of AI models using only world-class inference providers\n\nOmni uses a policy-based approach to model selection (after experimenting with different methods). Credits to @katanemo_ for their small routing model: katanemo/Arch-Router-1.5B\n\nComing next:\n‚Ä¢ MCP support with web search\n‚Ä¢ File support\n‚Ä¢ Omni routing selection improvements\n‚Ä¢ Customizable policies\n\nTry it out today at hf[dot] co/chat ü§ó",
          "kol": "reach_vb",
          "rank": 96,
          "followers": 33405,
          "likes": 381,
          "retweets": 51,
          "created_at": "Thu Oct 16 16:03:28 +0000 2025",
          "sentiment": "positive",
          "is_new": true
        },
        {
          "text": "Google has launched DeepSomatic, a powerful AI tool that finds cancer-causing genetic changes in tumor DNA. \n\nUnlike earlier methods, DeepSomatic works across multiple sequencing technologies and cancer types even in tricky cases like blood cancers where normal cells aren't available. \n\nTrained using a new high-quality dataset (CASTLE), the AI turns DNA data into images and uses neural networks to detect harmful mutations while filtering out errors. \n\nIt outperforms older tools, especially in catching harder-to-spot changes like insertions or deletions. \n\nGoogle hopes this tool will speed up cancer research and help doctors deliver more accurate, personalized treatments based on each tumor‚Äôs unique DNA profile.",
          "kol": "WesRothMoney",
          "rank": 107,
          "followers": 22808,
          "likes": 6,
          "retweets": 0,
          "created_at": "Fri Oct 17 11:00:02 +0000 2025",
          "sentiment": "neutral",
          "is_new": true
        }
      ]
    },
    "Lovable": {
      "mention_count": 9,
      "top_kols": [],
      "sentiment": {
        "neutral": 8,
        "positive": 1
      },
      "total_engagement": 1675,
      "sample_tweets": [
        {
          "text": "A year ago, we weren‚Äôt thinking much about enterprise. But it's now it's becoming a significant part of Lovable's revenue.\n\nEnterprises use Lovable to design, prototype, and build software faster. They collaborate across product, design, and engineering without losing speed.\n\nWe‚Äôve built the features that make it possible: security, SSO, collaboration, design systems, and the reliability large companies need. Several companies have told us Lovable is the fastest-adopted tool they‚Äôve ever rolled out internally.\n\nWe didn‚Äôt plan for this early on, but it has become a big part of where Lovable is growing.",
          "kol": "antonosika",
          "rank": 119,
          "followers": 64457,
          "likes": 192,
          "retweets": 7,
          "created_at": "Thu Oct 16 15:57:11 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "TL;DR Lovable just got a lot more powerful, and people like it so much the demand is spiking.\n\nWe‚Äôre now focused on expanding capacity and making Lovable Cloud even stronger.",
          "kol": "antonosika",
          "rank": 119,
          "followers": 64457,
          "likes": 26,
          "retweets": 0,
          "created_at": "Wed Oct 15 16:00:35 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "Since Lovable Cloud runs on Supabase, this growth contributed to doubling Supabase‚Äôs weekly database creation.\n\n//4",
          "kol": "antonosika",
          "rank": 119,
          "followers": 64457,
          "likes": 12,
          "retweets": 0,
          "created_at": "Wed Oct 15 16:00:29 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        }
      ]
    },
    "OfficialLoganK": {
      "mention_count": 8,
      "top_kols": [
        "testingcatalog"
      ],
      "sentiment": {
        "neutral": 8
      },
      "total_engagement": 271,
      "sample_tweets": [
        {
          "text": "@OfficialLoganK @GoogleAIStudio Aaaand a working model selector in the build section üî•",
          "kol": "testingcatalog",
          "rank": 19,
          "followers": 34948,
          "likes": 40,
          "retweets": 0,
          "created_at": "Thu Oct 16 16:42:37 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "@OfficialLoganK @GoogleAIStudio Logan can we get to know if Gemini Gemini Gemini is coming this month?",
          "kol": "Angaisb_",
          "rank": 24,
          "followers": 5505,
          "likes": 45,
          "retweets": 0,
          "created_at": "Thu Oct 16 16:37:44 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "@OfficialLoganK veo veo veo v?",
          "kol": "adonis_singh",
          "rank": 55,
          "followers": 13976,
          "likes": 13,
          "retweets": 0,
          "created_at": "Wed Oct 15 11:14:55 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        }
      ]
    },
    "Qwen": {
      "mention_count": 8,
      "top_kols": [],
      "sentiment": {
        "neutral": 7,
        "positive": 1
      },
      "total_engagement": 1434,
      "sample_tweets": [
        {
          "text": "iPhone„ÇÑMac„ÅßÈáçÈáèÁ¥öÁîªÂÉèÁîüÊàêAI„Çí„É≠„Éº„Ç´„É´ÂÆüË°å„Åß„Åç„Çã„ÄåDraw Things„Äç„Çí‰Ωø„Å£„Å¶„Åø„Åü„Çà„É¨„Éì„É•„Éº„ÄÅQwen Image„ÅÆ„Çà„ÅÜ„Å™Â§ßÂûã„É¢„Éá„É´„ÇÇÂÆüË°åÂèØËÉΩ\nhttps://t.co/0gJa1OO1xV",
          "kol": "gigazine",
          "rank": 26,
          "followers": 613564,
          "likes": 10,
          "retweets": 0,
          "created_at": "Fri Oct 17 03:13:19 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "Check out Qwen 3 VL 8b Thinking and Qwen 3 VL 8b Instruct vs. all the best AI models at: https://t.co/gxIFU9kamu",
          "kol": "arena",
          "rank": 114,
          "followers": 95099,
          "likes": 6,
          "retweets": 0,
          "created_at": "Tue Oct 14 18:33:16 +0000 2025",
          "sentiment": "positive",
          "is_new": false
        },
        {
          "text": "üö® New model drops!\n\nQwen 3 VL 8b Thinking and Qwen 3 VL 8b Instruct have entered the Text and Vision Arenas!\n\n@Alibaba_Qwen's Qwen3-VL just got lighter, but with the same full-stack capabilities, let's see how they rank on the leaderboards. \n\nüó≥Ô∏è Get prompting in Battle mode with your toughest real-world use cases, and through your votes, we'll know soon!",
          "kol": "arena",
          "rank": 114,
          "followers": 95099,
          "likes": 181,
          "retweets": 17,
          "created_at": "Tue Oct 14 18:33:16 +0000 2025",
          "sentiment": "neutral",
          "is_new": true
        }
      ]
    },
    "sama": {
      "mention_count": 8,
      "top_kols": [],
      "sentiment": {
        "neutral": 7,
        "negative": 1
      },
      "total_engagement": 369,
      "sample_tweets": [
        {
          "text": "@kate_rouch @OpenAI @sama @FidjiSimo Wonderful news! OpenAI will also make a big impact in the war against cancer. You are making the world a better place!",
          "kol": "DeryaTR_",
          "rank": 66,
          "followers": 320173,
          "likes": 5,
          "retweets": 0,
          "created_at": "Fri Oct 17 01:10:16 +0000 2025",
          "sentiment": "neutral",
          "is_new": true
        },
        {
          "text": "@sama Sam does it make you stay awake at night knowing users are going to make erotic fiction of you and Shrek being visited by 4o in a gimp outfit ?",
          "kol": "apples_jimmy",
          "rank": 87,
          "followers": 58706,
          "likes": 115,
          "retweets": 1,
          "created_at": "Wed Oct 15 03:29:56 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "@kate_rouch @OpenAI @sama @FidjiSimo congrats ü´∂",
          "kol": "rauchg",
          "rank": 134,
          "followers": 302880,
          "likes": 9,
          "retweets": 0,
          "created_at": "Thu Oct 16 17:44:35 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        }
      ]
    },
    "GaryMarcus": {
      "mention_count": 7,
      "top_kols": [
        "kimmonismus"
      ],
      "sentiment": {
        "neutral": 6,
        "negative": 1
      },
      "total_engagement": 299,
      "sample_tweets": [
        {
          "text": "@GaryMarcus @DeryaTR_ \"you used to be a scientist\"? I am nowhere near in the same league as @DeryaTR_ , but there are few academics who do as much for the future and science as he does. Not only is he a renowned researcher, but he also manages to make knowledge accessible to everyone and convey it in a language that everyone can understand.",
          "kol": "kimmonismus",
          "rank": 3,
          "followers": 86148,
          "likes": 48,
          "retweets": 0,
          "created_at": "Thu Oct 16 20:58:07 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "@GaryMarcus Just stop attacking me online. Or assuming that I am somehow always posting about you. This whole interaction makes me sad as we have some overlap in our views but it is impossible to discuss given both your approach &amp; the way X works. Hopefully next time in person will be better",
          "kol": "emollick",
          "rank": 21,
          "followers": 290491,
          "likes": 17,
          "retweets": 1,
          "created_at": "Fri Oct 17 02:45:53 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "@GaryMarcus I am at a loss. I respect your role (even if we disagree about some things) but you are so openly hostile on X all the time. It has become so unpleasant to see that you mention me, it is always a personal attack followed by your followers calling me names.\n\nJust stop, please.",
          "kol": "emollick",
          "rank": 21,
          "followers": 290491,
          "likes": 22,
          "retweets": 1,
          "created_at": "Fri Oct 17 02:35:18 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        }
      ]
    },
    "GPT-4": {
      "mention_count": 7,
      "top_kols": [
        "ArtificialAnlys",
        "slow_developer"
      ],
      "sentiment": {
        "neutral": 6,
        "positive": 1
      },
      "total_engagement": 845,
      "sample_tweets": [
        {
          "text": "we finally know how close we are to AGI\n\nthe paper tested the GPT-4 and GPT-5 on human cognitive abilities:\n\n> GPT-5 scored 58% toward AGI\n> GPT-4 scored 27%\n\nthe research also shows \"jagged intelligence\", which helps explain why AI can feel both very impressive and surprisingly weak at the same time",
          "kol": "slow_developer",
          "rank": 5,
          "followers": 51148,
          "likes": 397,
          "retweets": 60,
          "created_at": "Fri Oct 17 00:10:00 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "GPQA Diamond and ùúè¬≤-Bench Telecom (an agentic benchmark requiring models to act in a customer service role) both show outsized performance for GPT-5 and o3 compared to GPT-4.1, but while the reasoning models cost >10x to run GPQA, in ùúè¬≤‚Äôs customer service environment they cost about the same as GPT-4.1. o3 and GPT-4.1 now have equal token costs, so these differences are driven entirely by efficiency.",
          "kol": "ArtificialAnlys",
          "rank": 20,
          "followers": 60488,
          "likes": 16,
          "retweets": 1,
          "created_at": "Wed Oct 15 20:39:21 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "I use a Mac app called \"Spokenly\" to dictate everything, so I move at the speed of speech. Right now I'm finding the online GPT-4.0 mini transcribe model the best.",
          "kol": "maccaw",
          "rank": 97,
          "followers": 39332,
          "likes": 9,
          "retweets": 0,
          "created_at": "Thu Oct 16 17:20:33 +0000 2025",
          "sentiment": "positive",
          "is_new": false
        }
      ]
    },
    "testingcatalog": {
      "mention_count": 7,
      "top_kols": [],
      "sentiment": {
        "neutral": 7
      },
      "total_engagement": 161,
      "sample_tweets": [
        {
          "text": "@k_kohlbrenner @testingcatalog @OpenAI @ChatGPTapp Thank you",
          "kol": "btibor91",
          "rank": 25,
          "followers": 31609,
          "likes": 27,
          "retweets": 1,
          "created_at": "Thu Oct 16 20:58:27 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "@testingcatalog @GoogleAIStudio yes, very fun for testing",
          "kol": "OfficialLoganK",
          "rank": 33,
          "followers": 216323,
          "likes": 35,
          "retweets": 0,
          "created_at": "Thu Oct 16 16:47:11 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "@FeltSteam @k_kohlbrenner @btibor91 @testingcatalog @OpenAI @ChatGPTapp Yeah, maybe GPT-5.5.  It's just hard for me to imagine them releasing GPT-5 and GPT-6 within a few months of each other - from a marketing perspective.",
          "kol": "deredleritt3r",
          "rank": 154,
          "followers": 4076,
          "likes": 7,
          "retweets": 0,
          "created_at": "Thu Oct 16 21:47:30 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        }
      ]
    },
    "eliebakouch": {
      "mention_count": 6,
      "top_kols": [
        "karpathy"
      ],
      "sentiment": {
        "neutral": 6
      },
      "total_engagement": 82,
      "sample_tweets": [
        {
          "text": "@eliebakouch @rasbt Very early on in the project I did a small run with/without QK norm and found that it helped. Same for the embedding weight sharing. I'll retry!\n\nI'm not tied to any details of the model and they weren't chosen any more carefully than a single run, I spent most of the time just arranging the harness. Now it's a good time to experiment again.",
          "kol": "karpathy",
          "rank": 7,
          "followers": 1405116,
          "likes": 53,
          "retweets": 1,
          "created_at": "Mon Oct 13 16:23:01 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "@eliebakouch also wrt attention, check out gated attention, free lunch at all scales essentially.",
          "kol": "kalomaze",
          "rank": 155,
          "followers": 19566,
          "likes": 5,
          "retweets": 0,
          "created_at": "Thu Oct 16 14:49:21 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "@eliebakouch i see hybrids as mainly being kinda proto-NSA or sparse attention in some ways. mamba is unique in the sense that it could compress more, but ends up not",
          "kol": "kalomaze",
          "rank": 155,
          "followers": 19566,
          "likes": 5,
          "retweets": 0,
          "created_at": "Thu Oct 16 14:45:01 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        }
      ]
    },
    "GeminiApp": {
      "mention_count": 6,
      "top_kols": [],
      "sentiment": {
        "neutral": 6
      },
      "total_engagement": 1726,
      "sample_tweets": [
        {
          "text": "@McLarenF1 @GeminiApp üß°",
          "kol": "OfficialLoganK",
          "rank": 33,
          "followers": 216323,
          "likes": 14,
          "retweets": 0,
          "created_at": "Wed Oct 15 23:49:58 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "Veo 3 is the state-of-the-art in video models. Veo 3.1 is our new big upgrade with enhanced realism, richer audio, scene extension, better narrative control, more precise editing capabilities &amp; much more. Enjoy creating with it at https://t.co/QgTpxTKAOi and in the @GeminiApp !",
          "kol": "demishassabis",
          "rank": 48,
          "followers": 495537,
          "likes": 1446,
          "retweets": 224,
          "created_at": "Wed Oct 15 16:44:05 +0000 2025",
          "sentiment": "neutral",
          "is_new": true
        },
        {
          "text": "@GeminiApp At least compensate him with an ultra sub , he deserves that",
          "kol": "chetaslua",
          "rank": 132,
          "followers": 6886,
          "likes": 13,
          "retweets": 0,
          "created_at": "Fri Oct 17 00:13:51 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        }
      ]
    },
    "gpt-5": {
      "mention_count": 6,
      "top_kols": [],
      "sentiment": {
        "neutral": 6
      },
      "total_engagement": 352,
      "sample_tweets": [
        {
          "text": "@flowersslop this is a weak indication imo. this for example doesn't happen with gpt-5 thinking or pro. https://t.co/TyELRAviyB",
          "kol": "adonis_singh",
          "rank": 55,
          "followers": 13976,
          "likes": 16,
          "retweets": 0,
          "created_at": "Thu Oct 16 23:10:07 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "I asked gpt-5-pro to rank the major labs CEOs\n\nputting moonshot so low is a crime https://t.co/gVznWudj4T",
          "kol": "adonis_singh",
          "rank": 55,
          "followers": 13976,
          "likes": 96,
          "retweets": 3,
          "created_at": "Sun Oct 12 22:40:00 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "ÂÖ®ÁêÉÂà∞Â∫ïÊúâÂ§öÂ∞ë‰∫∫ÂºÄÈÄö‰∫Ü 200 ÁæéÈáë/ÊúàÁöÑ chatgpt proÔºüü§£\n\nËÆ© gpt-5 pro Ê†πÊçÆ openai ÊúÄÊñ∞Êî∂ÂÖ•ÂíåÁî®Êà∑Êï∞ÊçÆ‰º∞ÁÆó plus Âíå pro ‰ºöÂëòÁöÑ‰∫∫Êï∞„ÄÇ\n\n‰πãÂâçÊé®‰∏äÂ§ßÂÆ∂ÁªèÂ∏∏ËÆ®ËÆ∫Âà∞Â∫ïÊúâÂ§öÂ∞ë plus Áî®Êà∑ÔºåÊúâÂ§öÂ∞ë pro Áî®Êà∑ÔºåÂü∫Êú¨Á†¥Ê°à‰∫ÜÔºågpt-5 ÁöÑÊï∞ÊçÆÂü∫Êú¨Èù†Ë∞±„ÄÇ\n\nchatgpt 8 ‰∫øÁî®Êà∑‰∏≠Ôºå‰ªòË¥πÁî®Êà∑Êé•Ëøë 4000 ‰∏áÔºå‰ªòË¥πÁéá 5%„ÄÇÂü∫Êú¨‰∏ä‰πüÊòØ‰∏§‰∏™Ê†áÂáÜÂ∑ÆÂ∑¶Âè≥ÁöÑÂ∞ëÊï∞Ê¥æ‰∫Ü„ÄÇ\n\npro Áî®Êà∑Á∫¶ 20 ‰∏áÔºåÂ§ßÊ¶ÇÊòØ 200 ‰∏™ plus Áî®Êà∑ÈáåÊúâ‰∏Ä‰∏™ pro ÂÜ§ÁßçÔºàÂÆûÈôÖ‰ΩøÁî®È¢ùÂ∫¶ÂæÄÂæÄËææ‰∏çÂà∞ 200Ôºå‰∏çÂ∞ëÈÉΩÊµ™Ë¥πÊéâ‰∫Üü§£Ôºâ„ÄÇ\n\nÊÉ≥Ê≥ïÔºöai Ê∏óÈÄèÁéáËøòÊòØÁõ∏ÂΩì‰ΩéÁöÑÔºå‰ª•‰ªòË¥πËÆ¢ÈòÖ‰∏∫ÁïåÂÆöÊ†áÂáÜÁöÑËØù„ÄÇai Â§¥‰∏äËøòÊúâ‰∏çÂ∞èÁöÑÂèëÂ±ïÁ©∫Èó¥„ÄÇ\n\nÊâÄ‰ª•Ôºånvda ÂèØ‰ª• 10 ‰∏á‰∫øÂêóü•∫",
          "kol": "howie_serious",
          "rank": 121,
          "followers": 44843,
          "likes": 142,
          "retweets": 13,
          "created_at": "Thu Oct 16 13:08:40 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        }
      ]
    },
    "chatgpt": {
      "mention_count": 6,
      "top_kols": [],
      "sentiment": {
        "neutral": 5,
        "positive": 1
      },
      "total_engagement": 697,
      "sample_tweets": [
        {
          "text": "ÊúâË∂£ÁöÑÁé∞Ë±°Ôºöchatgpt Êó•Ê¥ª 2000 ‰∏á„ÄÇ\n\nÂèØÊòØ plus Êúâ 4000 ‰∏á„ÄÇ\n\nÊâÄ‰ª•ÔºåÊúâ‰∏ÄÂçäplus Áî®Êà∑‰ªò‰∫Ü 20 ÁæéÈáëËÆ¢ÈòÖchatgptÔºå‰ΩÜÂç¥Ê≤°ÊúâÂ§©Â§©Áî®Ôºü https://t.co/wd0qFamYSf",
          "kol": "howie_serious",
          "rank": 121,
          "followers": 44843,
          "likes": 77,
          "retweets": 5,
          "created_at": "Thu Oct 16 13:51:02 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "ÂÖ®ÁêÉÂà∞Â∫ïÊúâÂ§öÂ∞ë‰∫∫ÂºÄÈÄö‰∫Ü 200 ÁæéÈáë/ÊúàÁöÑ chatgpt proÔºüü§£\n\nËÆ© gpt-5 pro Ê†πÊçÆ openai ÊúÄÊñ∞Êî∂ÂÖ•ÂíåÁî®Êà∑Êï∞ÊçÆ‰º∞ÁÆó plus Âíå pro ‰ºöÂëòÁöÑ‰∫∫Êï∞„ÄÇ\n\n‰πãÂâçÊé®‰∏äÂ§ßÂÆ∂ÁªèÂ∏∏ËÆ®ËÆ∫Âà∞Â∫ïÊúâÂ§öÂ∞ë plus Áî®Êà∑ÔºåÊúâÂ§öÂ∞ë pro Áî®Êà∑ÔºåÂü∫Êú¨Á†¥Ê°à‰∫ÜÔºågpt-5 ÁöÑÊï∞ÊçÆÂü∫Êú¨Èù†Ë∞±„ÄÇ\n\nchatgpt 8 ‰∫øÁî®Êà∑‰∏≠Ôºå‰ªòË¥πÁî®Êà∑Êé•Ëøë 4000 ‰∏áÔºå‰ªòË¥πÁéá 5%„ÄÇÂü∫Êú¨‰∏ä‰πüÊòØ‰∏§‰∏™Ê†áÂáÜÂ∑ÆÂ∑¶Âè≥ÁöÑÂ∞ëÊï∞Ê¥æ‰∫Ü„ÄÇ\n\npro Áî®Êà∑Á∫¶ 20 ‰∏áÔºåÂ§ßÊ¶ÇÊòØ 200 ‰∏™ plus Áî®Êà∑ÈáåÊúâ‰∏Ä‰∏™ pro ÂÜ§ÁßçÔºàÂÆûÈôÖ‰ΩøÁî®È¢ùÂ∫¶ÂæÄÂæÄËææ‰∏çÂà∞ 200Ôºå‰∏çÂ∞ëÈÉΩÊµ™Ë¥πÊéâ‰∫Üü§£Ôºâ„ÄÇ\n\nÊÉ≥Ê≥ïÔºöai Ê∏óÈÄèÁéáËøòÊòØÁõ∏ÂΩì‰ΩéÁöÑÔºå‰ª•‰ªòË¥πËÆ¢ÈòÖ‰∏∫ÁïåÂÆöÊ†áÂáÜÁöÑËØù„ÄÇai Â§¥‰∏äËøòÊúâ‰∏çÂ∞èÁöÑÂèëÂ±ïÁ©∫Èó¥„ÄÇ\n\nÊâÄ‰ª•Ôºånvda ÂèØ‰ª• 10 ‰∏á‰∫øÂêóü•∫",
          "kol": "howie_serious",
          "rank": 121,
          "followers": 44843,
          "likes": 142,
          "retweets": 13,
          "created_at": "Thu Oct 16 13:08:40 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "chatgpt Âç≥Â∞ÜÊé®Âá∫ prompt library ÂäüËÉΩ„ÄÇÁªà‰∫éÔºåprompt ‰Ωú‰∏∫‰∏ÄÁßçÁü•ËØÜËΩΩ‰ΩìÔºå‰πüÂèØ‰ª•Âú® chatgpt ÈáåÈù¢Ë¢´ÁÆ°ÁêÜËµ∑Êù•Âï¶„ÄÇ\n\nËøôËÉåÂêéÊòØÂêå‰∏Ä‰∏™ÈóÆÈ¢òÁöÑ n Ê¨°Â∞ùËØïÔºö‰ªª‰ΩïÈáçÂ§ç‰ΩøÁî® 3 Ê¨°‰ª•‰∏äÁöÑ promptÔºåÈÉΩÂ∫îËØ•Â≠òËµ∑Êù•ÔºåÂõ∫ÂÆö‰∏ãÊù•ÔºåËÆ©Áî®Êà∑ÈÅøÂÖçÈáçÂ§çÂä≥Âä®ÔºåËÉΩÂø´ÈÄüË∞ÉÁî®„ÄÇ\n\nËøôÊ†∑ÊâçËÉΩÈôç‰ΩéËÆ§Áü•Ë¥üËç∑ÔºåÂáèÂ∞ëÂ∑•ÂÖ∑Êë©Êì¶ÊèêÈ´ò‰ΩøÁî®Êó∂ÁöÑÂ§öÂ∑¥ËÉ∫„ÄÇ\n\nÁ¨¨‰∏ÄÊ¨°Â∞ùËØïÔºåÊòØ GPTs„ÄÇÂçí„ÄÇ\n\nÁ¨¨‰∫åÊ¨°ÊòØÁé∞Âú®ÁöÑ projects„ÄÇÊàëËá™Â∑±ÊääÂ∏∏Áî®ÁöÑ prompt ÈÉΩÂõ∫ÂÆö‰∏∫‰∏Ä‰∏™ÂçïÁã¨ÁöÑ project„ÄÇÂæàÂ•ΩÁî®„ÄÇ‰ΩÜÊàëËßâÂæóÂπ∂‰∏çÊôÆÂèä„ÄÇËÄå‰∏î‰ºöÈÄ†Êàê projects Êï∞ÈáèËøáÂ§ö„ÄÇ‰∏çÁÆóÊàêÂäüÂêß„ÄÇ\n\nÁé∞Âú®ÁöÑÊñπÊ°àÁ±ª‰ºº comet ÊµèËßàÂô®ÁöÑ skills„ÄÇÁî®/Ë∞ÉÂá∫ÈáçÂ§ç‰ΩøÁî®ÁöÑ prompt„ÄÇ\n\nËøô‰∏™ÊñπÊ°àÊòØÂØπ projects ÊñπÊ°àÁöÑÊûÅÂ•ΩË°•ÂÖÖ„ÄÇÊúüÂæÖÊó©ÁÇπÂèëÂ∏É„ÄÇüëè",
          "kol": "howie_serious",
          "rank": 121,
          "followers": 44843,
          "likes": 118,
          "retweets": 15,
          "created_at": "Thu Oct 16 11:00:13 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        }
      ]
    },
    "Midjourney": {
      "mention_count": 5,
      "top_kols": [],
      "sentiment": {
        "positive": 1,
        "neutral": 4
      },
      "total_engagement": 275,
      "sample_tweets": [
        {
          "text": "I can't get Seedream 4.0 to be as aesthetic as Midjourney after weeks trying, even when giving reference images (I know the prompt isn't the best but trust me, I've tried many things)\n\nI guess MJ will never have competition https://t.co/UhIThepHFA",
          "kol": "Angaisb_",
          "rank": 24,
          "followers": 5505,
          "likes": 23,
          "retweets": 0,
          "created_at": "Thu Oct 16 23:29:33 +0000 2025",
          "sentiment": "positive",
          "is_new": false
        },
        {
          "text": "Midjourney --sref 701577734 https://t.co/mO5YlKlVay",
          "kol": "HBCoop_",
          "rank": 38,
          "followers": 51945,
          "likes": 10,
          "retweets": 0,
          "created_at": "Fri Oct 17 05:11:06 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "Veo 3.1 + Midjourney + 1 hour https://t.co/7TBp4LFeFj",
          "kol": "ciguleva",
          "rank": 60,
          "followers": 76332,
          "likes": 171,
          "retweets": 5,
          "created_at": "Wed Oct 15 20:50:01 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        }
      ]
    },
    "Google AI": {
      "mention_count": 5,
      "top_kols": [],
      "sentiment": {
        "neutral": 5
      },
      "total_engagement": 9838,
      "sample_tweets": [
        {
          "text": "Friendly reminder that you can get Google AI Pro for free if you're a student.\n\nYou have access to:\n\n- NotebookLM with higher limits\n- Gemini app with 2.5 Pro and Veo\n- Gemini in Gmail, Docs, Sheets, etc.\n- Deep Research\n- Jules with higher limits\n- Homework help / Exam prep\n- 2 TB Storage in Drive, etc.\n\nAvailable in many countries (and continuing to expand).\n\nDetails below",
          "kol": "itsPaulAi",
          "rank": 45,
          "followers": 219511,
          "likes": 498,
          "retweets": 50,
          "created_at": "Sat Oct 11 21:47:41 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "@bhancock_ai @thegenaigirl @KnightHacks Team #3: Marcus and Sita\n\nUniversity of Waterloo CS student @_marcus_ng partners with Sita Lakshmi, a Google AI agent/ADK specialist. They're bringing a creative flair with a unique UI where each agent is a section of a musical band, working in harmony to manage your finances. https://t.co/G6Fy1wZ9mD",
          "kol": "GoogleCloudTech",
          "rank": 71,
          "followers": 1291763,
          "likes": 6,
          "retweets": 1,
          "created_at": "Mon Oct 13 19:00:04 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "AI„ÅåÂ¢ó„Åà„Åô„Åé„Åü„ÅÆ„Åß\n„Çø„Çπ„ÇØÊØé„Ç™„Çπ„Çπ„É°‰Ωø„ÅÑÂàÜ„ÅëÔºö „Ö§\n\nË®ò‰∫ãÂü∑Á≠Ü - GPT-5 pro, GPT-4.5\n„É™„Çµ„Éº„ÉÅ - ChatGPT DeepResearch / „Ç®„Éº„Ç∏„Çß„É≥„Éà\n„É™„Çµ„Éº„ÉÅ„Åã„Çâ„ÅÆÂàÜÊûê - Manus\nÊ§úÁ¥¢ - Grok 4\n„Ç≥„Éº„Éá„Ç£„É≥„Ç∞ - GPT-5 codex high\n„Ç¶„Çß„ÉñÊìç‰ΩúAI - Manus, Perplexity Comet\nÂãïÁîªÂàÜÊûê - Gemini 2.5 pro\nÁîªÂÉèÁîüÊàê - Higgsfield, Seedream 4.0\nÂãïÁîªÁîüÊàê - Sora2 pro\nÁÑ°Êñô - Google AI studio",
          "kol": "SuguruKun_ai",
          "rank": 143,
          "followers": 88341,
          "likes": 109,
          "retweets": 6,
          "created_at": "Fri Oct 17 08:08:33 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        }
      ]
    },
    "BjarturTomas": {
      "mention_count": 5,
      "top_kols": [],
      "sentiment": {
        "neutral": 5
      },
      "total_engagement": 231,
      "sample_tweets": [
        {
          "text": "@BjarturTomas Re ‚Äúdeep ai psychosis‚Äù, I don‚Äôt think that‚Äôs it. Worked under him for 5 years pre AI. He‚Äôs just like this\n\nhttps://t.co/S5WtzdISi7",
          "kol": "theo",
          "rank": 46,
          "followers": 248507,
          "likes": 134,
          "retweets": 0,
          "created_at": "Fri Oct 17 04:03:17 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "@an_interstice @BjarturTomas yeah I think you‚Äôre being a bit of a dick\n\nit‚Äôs Twitter - you can talk about your thoughts there\n\nthey‚Äôre not writing a paper in Nature",
          "kol": "anthrupad",
          "rank": 249,
          "followers": 14824,
          "likes": 22,
          "retweets": 0,
          "created_at": "Fri Oct 17 03:49:57 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "@BjarturTomas naw\nall you have to go off of is curious fanboying over stuff?",
          "kol": "anthrupad",
          "rank": 249,
          "followers": 14824,
          "likes": 10,
          "retweets": 0,
          "created_at": "Fri Oct 17 03:33:41 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        }
      ]
    },
    "drop": {
      "mention_count": 5,
      "top_kols": [],
      "sentiment": {
        "neutral": 5
      },
      "total_engagement": 500,
      "sample_tweets": [
        {
          "text": "@dejavucoder Yeah, every trailer drop has to be exponential better from that one on",
          "kol": "waitin4agi_",
          "rank": 57,
          "followers": 217035,
          "likes": 36,
          "retweets": 0,
          "created_at": "Mon Oct 13 13:38:57 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "why does the chinese doordash continue to drop models https://t.co/NaCUU3sZG1",
          "kol": "xeophon_",
          "rank": 92,
          "followers": 8376,
          "likes": 81,
          "retweets": 4,
          "created_at": "Fri Oct 17 08:00:54 +0000 2025",
          "sentiment": "neutral",
          "is_new": false
        },
        {
          "text": "üö®New model drop into the Top 10!\nüñºÔ∏è @MicrosoftAI just entered the Image Arena with MAI-Image-1.\n\nCommunity votes are already rolling in, and MAI-Image-1 has broken into the Top 10. It‚Äôs currently ranked #9, tied with Seedream 3! \n\nMAI-Image-1 is now live in Direct Chat for early access on LMArena.",
          "kol": "arena",
          "rank": 114,
          "followers": 95099,
          "likes": 196,
          "retweets": 31,
          "created_at": "Mon Oct 13 20:08:44 +0000 2025",
          "sentiment": "neutral",
          "is_new": true
        }
      ]
    }
  },
  "new_products": {
    "Claude": {
      "mention_count": 17,
      "first_mentioned": "Fri Oct 17 00:32:05 +0000 2025",
      "discoverers": [
        {
          "kol": "ArtificialAnlys",
          "rank": 20
        },
        {
          "kol": "ArtificialAnlys",
          "rank": 20
        },
        {
          "kol": "btibor91",
          "rank": 25
        },
        {
          "kol": "btibor91",
          "rank": 25
        },
        {
          "kol": "GoogleCloudTech",
          "rank": 71
        },
        {
          "kol": "maccaw",
          "rank": 97
        },
        {
          "kol": "WesRothMoney",
          "rank": 107
        },
        {
          "kol": "WesRothMoney",
          "rank": 107
        },
        {
          "kol": "arena",
          "rank": 114
        },
        {
          "kol": "rileybrown_ai",
          "rank": 123
        },
        {
          "kol": "levie",
          "rank": 139
        },
        {
          "kol": "poe_platform",
          "rank": 161
        },
        {
          "kol": "Prathkum",
          "rank": 163
        },
        {
          "kol": "DeepLearningAI",
          "rank": 184
        },
        {
          "kol": "DeepLearningAI",
          "rank": 184
        },
        {
          "kol": "mikeyk",
          "rank": 199
        },
        {
          "kol": "karinanguyen_",
          "rank": 204
        }
      ],
      "sample_tweets": [
        "Claude 4.5 Haiku is a significant intelligence uplift compared to Claude 3.5 Haiku. Compared to Claude 3.5 Haiku, there is a +26 p.p. and +24 p.p. increase in GPQA-Diamond scores for Thinking and Non-Thinking modes, respectively. Claude 3.5 Haiku is a non-reasoning model, and it was released ~11 months prior to the release of Claude 4.5 Haiku",
        "Anthropic launches their first Haiku model in 11 months - Claude 4.5 Haiku jumps 35 points in Artificial Analysis Intelligence Index to become relevant again\n\nClaude 4.5 Haiku is 3x cheaper per token than Claude 4.5 Sonnet. Running the Artificial Analysis Intelligence Index costs $262 with Haiku vs. $817 with Sonnet (~3x more) - full cost breakdown in the thread below.\n\nThere is a stronger case for 4.5 Haiku‚Äôs intelligence/cost positioning than 3.5 Haiku, but there is a competitive field of cheaper alternatives with similar intelligence that may make more sense for developers without a reason to need a Claude model specifically - including gpt-oss-120b (reasoning high, ~$75) and Grok 4 Fast (~$40). Claude 4.5 Haiku is the most cost-effective way to access ‚ÄòClaude‚Äô but is not the most cost effective model for its level of intelligence.\n\nKey benchmarking results:\n‚û§üß† Model Intelligence: In reasoning mode, Claude 4.5 Haiku scores 55 on the Artificial Analysis Intelligence Index. This is 8 points lower than Claude 4.5 Sonnet (Thinking) and 4 points lower than Claude 4.1 Opus (Thinking). Claude 4.5 Haiku (Thinking) places marginally ahead of Gemini 2.5 Flash (Reasoning, 54) but behind other reasoning models such as Qwen3 235B 2507 (57), DeepSeek V3.2 Exp (57), and GLM 4.6 (56)\n‚û§üìà Intelligence Uplift: Anthropic released Claude 3.5 Haiku in November 2024, ~11 months before the release of Claude 4.5 Haiku. Claude 4.5 Haiku is a significant improvement in intelligence compared to Claude 3.5 Haiku, scoring 67% on GPQA Diamond in reasoning mode (compared to 41% for Claude 3.5 Haiku)\n‚û§‚öôÔ∏è Notable Strengths: In reasonign mode, Claude 4.5 Haiku performs well in long-context reasoning (70% on AA-LCR, behind only GPT-5 High) and coding (43%, matching GPT-5 High and Gemini 2.5 Pro)\n‚û§‚ö° Non-Reasoning Performance: In non-reasoning mode, Claude 4.5 Haiku scores 42 on the Artificial Analysis Intelligence Index. This places the model in line with GPT-5 (minimal, 43) but behind Gemini 2.5 Flash (non-reasoning, 47)\n‚û§üí≤ Pricing: Claude 4.5 Haiku is priced at $1/$5 per 1M input/output tokens, which makes it 3x cheaper compared to Claude 4.5 Sonnet (priced at $3/$15 per 1M input/output tokens)\n‚û§‚öôÔ∏è Token Efficiency: Anthropic‚Äôs Claude models continue to be more token-efficient than all other reasoning models. For Claude 4.5 Haiku (Thinking) -evaluated with a maximum reasoning budget of 64k tokens - we see the model use 39M output tokens to run the Artificial Analysis Intelligence Index. Its token usage is lower than Claude 4.5 Sonnet (42M) but higher than Claude 4.1 Opus (30M) in thinking mode\n\nKey model details:\n\n‚û§üìè¬†Context Window: 200K tokens. This is equivalent to Claude 4.5 Sonnet\n‚û§üåê¬†Availability: Claude 4.5 Haiku is available via Anthropic‚Äòs API, Google Vertex and Amazon Bedrock. Claude 4.5 Haiku is also available via Claude, and Claude Code"
      ]
    },
    "OpenAI": {
      "mention_count": 14,
      "first_mentioned": "Fri Oct 17 00:33:17 +0000 2025",
      "discoverers": [
        {
          "kol": "ai_for_success",
          "rank": 9
        },
        {
          "kol": "Angaisb_",
          "rank": 24
        },
        {
          "kol": "Angaisb_",
          "rank": 24
        },
        {
          "kol": "DeryaTR_",
          "rank": 66
        },
        {
          "kol": "mattshumer_",
          "rank": 67
        },
        {
          "kol": "AndrewCurran_",
          "rank": 84
        },
        {
          "kol": "freeCodeCamp",
          "rank": 90
        },
        {
          "kol": "deredleritt3r",
          "rank": 154
        },
        {
          "kol": "deredleritt3r",
          "rank": 154
        },
        {
          "kol": "DeepLearningAI",
          "rank": 184
        },
        {
          "kol": "DeepLearningAI",
          "rank": 184
        },
        {
          "kol": "karinanguyen_",
          "rank": 204
        },
        {
          "kol": "johncoogan",
          "rank": 224
        },
        {
          "kol": "legit_api",
          "rank": 259
        }
      ],
      "sample_tweets": [
        "OpenAI CEO: We‚Äôll allow erot!ca.\nGoogle CEO: We have built an AI model that discovered a new cancer therapy pathway.  \n\nDifferent priorities.  \nTLDR:  \n> Google DeepMind and Yale released Cell2Sentence-Scale 27B, a 27B parameter Gemma-based model for single-cell analysis.  \n> The model predicted and confirmed a new way to make ‚Äúcold‚Äù tumors visible to the immune system.  \n> A breakthrough in AI-driven cancer research and future drug discovery.",
        "@chatgpt21 Gemini 3.0 Pro will be a new baseline and they can't just wait until February to compete with it (imo)\n\nAlso, at least for me GPT-5 wasn't the jump we expected, OpenAI knew that, but GPT-5 was meant to be used by all users, not only paid users\n\nMaybe they were already working on this much better model but they've been trying to optimize compute and wait for more GPUs"
      ]
    },
    "ChatGPT": {
      "mention_count": 10,
      "first_mentioned": "Fri Oct 17 06:20:00 +0000 2025",
      "discoverers": [
        {
          "kol": "karpathy",
          "rank": 7
        },
        {
          "kol": "btibor91",
          "rank": 25
        },
        {
          "kol": "freeCodeCamp",
          "rank": 90
        },
        {
          "kol": "reach_vb",
          "rank": 96
        },
        {
          "kol": "VraserX",
          "rank": 118
        },
        {
          "kol": "TheRealAdamG",
          "rank": 149
        },
        {
          "kol": "DeepLearningAI",
          "rank": 184
        },
        {
          "kol": "karinanguyen_",
          "rank": 204
        },
        {
          "kol": "johncoogan",
          "rank": 224
        },
        {
          "kol": "johncoogan",
          "rank": 224
        }
      ],
      "sample_tweets": [
        "nanochat d32, i.e. the depth 32 version that I specced for $1000, up from $100 has finished training after ~33 hours, and looks good. All the metrics go up quite a bit across pretraining, SFT and RL. CORE score of 0.31 is now well above GPT-2 at ~0.26. GSM8K went ~8% -> ~20%, etc. So that's encouraging.\n\nThe model is pretty fun to talk to, but judging from some early interactions I think people have a little bit too much expectation for these micro models. There is a reason that frontier LLM labs raise billions to train their models. nanochat models cost $100 - $1000 to train from scratch. The $100 nanochat is 1/1000th the size of GPT-3 in parameters, which came out 5 years ago. So I urge some perspective. Talking to micro models you have to imagine you're talking to a kindergarten child. They say cute things, wrong things, they are a bit confused, a bit naive, sometimes a little non-sensical, they hallucinate a ton (but it's amusing), etc.\n\nFull detail/report on this run is here:\nhttps://t.co/nWbfKOZLIg\nAnd I pushed the new script run1000 sh to the nanochat repo if anyone would like to reproduce. Totally understand if you'd like to spend $1000 on something else :D\n\nIf you like, I am currently hosting the model so you can talk to it on a webchat as you'd talk to ChatGPT. I'm not going to post the URL here because I'm afraid it will get crushed. You'll have to look for it if you care enough. I'm also attaching a few funny conversations I had with the model earlier into the image, just to give a sense.\n\nNext up, I am going to do one pass of tuning and optimizing the training throughput, then maybe return back to scaling and maybe training the next tier of a bigger model.",
        "ChatGPT web app has a new \"integrated voice mode\" experiment - directly in the prompt composer, allowing you to stay where you are in your conversation or on the dashboard, instead of switching to a separate voice mode screen https://t.co/Gn9co6qxPQ"
      ]
    },
    "Gemini": {
      "mention_count": 10,
      "first_mentioned": "Fri Oct 10 20:41:12 +0000 2025",
      "discoverers": [
        {
          "kol": "ai_for_success",
          "rank": 9
        },
        {
          "kol": "ArtificialAnlys",
          "rank": 20
        },
        {
          "kol": "ArtificialAnlys",
          "rank": 20
        },
        {
          "kol": "Angaisb_",
          "rank": 24
        },
        {
          "kol": "OfficialLoganK",
          "rank": 33
        },
        {
          "kol": "_philschmid",
          "rank": 52
        },
        {
          "kol": "_philschmid",
          "rank": 52
        },
        {
          "kol": "GoogleCloudTech",
          "rank": 71
        },
        {
          "kol": "Prathkum",
          "rank": 163
        },
        {
          "kol": "ThomasOrTK",
          "rank": 223
        }
      ],
      "sample_tweets": [
        "üö® Google has rolled out a new unified playground experience in AI Studio, combining Chat, GenMedia, and Live in a single interface.  \n\nAll set for Gemini 3.0? What do you think?\nhttps://t.co/LoUcKsdGEG",
        "Riverflow 1 from Sourceful debuts at #1 in the Artificial Analysis Image Editing Leaderboard for All Listings, using a vision language model trained by Sourceful to allow chain of thought reasoning in combination with a third-party open weights diffusion model\n\nRiverflow 1 demonstrates strong generalized editing performance in our arena, with improved output quality at the trade-off of longer run times and higher pricing compared to current leading Image Editing models.\n\nRiverflow 1 is available on @RunwareAI  priced at $66/1k images, a premium above Gemini 2.5 Flash (Nano-Banana) at $39/1k images and Seedream 4.0 at $30/1k images. All components of the Riverflow system deployed on Runware's GPUs. There is also a riverflow-1-mini variant of the offering priced at $50/1k images.\n\nRiverflow 1 is the debut image editing offering from @sourceful, a UK-based brand and packaging design platform backed by Index Ventures and Dylan Field, where it serves as the default image editing option.\n\nLeaderboard note: Riverflow 1 is listed in the ‚ÄúAll‚Äù tab, separate to our default ‚ÄúFirst Party Foundation Models‚Äù view. Our goal is to reflect and recognize Sourceful‚Äôs innovation with Riverflow 1 while maintaining rankings for image editing offerings that we assess to be first-party foundation models.\n\nSee below for comparisons between Riverflow 1 and other leading models in our Image Editing Arena üßµ"
      ]
    },
    "launched": {
      "mention_count": 9,
      "first_mentioned": "Fri Oct 17 09:00:03 +0000 2025",
      "discoverers": [
        {
          "kol": "AndrewCurran_",
          "rank": 84
        },
        {
          "kol": "reach_vb",
          "rank": 96
        },
        {
          "kol": "WesRothMoney",
          "rank": 107
        },
        {
          "kol": "WesRothMoney",
          "rank": 107
        },
        {
          "kol": "antonosika",
          "rank": 119
        },
        {
          "kol": "MarioNawfal",
          "rank": 131
        },
        {
          "kol": "MarioNawfal",
          "rank": 131
        },
        {
          "kol": "SBSNews",
          "rank": 200
        },
        {
          "kol": "iamfakhrealam",
          "rank": 211
        }
      ],
      "sample_tweets": [
        "Axios broke this a few minutes ago. This is the first person to join the OpenAI for Science initiative launched by Kevin Weil.",
        "BOOM: We've just re-launched HuggingChat v2 üí¨ - 115 open source models in a single interface is stronger than ChatGPT üî•\n\nIntroducing: HuggingChat Omni üí´\n> Select the best model for every prompt automatically üöÄ\n> Automatic model selection for your queries\n> 115 models available across 15 providers including @GroqInc, @CerebrasSystems, @togethercompute, @novita_labs, and more\n\nPowered by HF Inference Providers ‚Äî access hundreds of AI models using only world-class inference providers\n\nOmni uses a policy-based approach to model selection (after experimenting with different methods). Credits to @katanemo_ for their small routing model: katanemo/Arch-Router-1.5B\n\nComing next:\n‚Ä¢ MCP support with web search\n‚Ä¢ File support\n‚Ä¢ Omni routing selection improvements\n‚Ä¢ Customizable policies\n\nTry it out today at hf[dot] co/chat ü§ó"
      ]
    },
    "Anthropic": {
      "mention_count": 7,
      "first_mentioned": "Fri Oct 17 09:00:03 +0000 2025",
      "discoverers": [
        {
          "kol": "testingcatalog",
          "rank": 19
        },
        {
          "kol": "ArtificialAnlys",
          "rank": 20
        },
        {
          "kol": "btibor91",
          "rank": 25
        },
        {
          "kol": "WesRothMoney",
          "rank": 107
        },
        {
          "kol": "poe_platform",
          "rank": 161
        },
        {
          "kol": "DeepLearningAI",
          "rank": 184
        },
        {
          "kol": "DeepLearningAI",
          "rank": 184
        }
      ],
      "sample_tweets": [
        "Anthropic released Microsoft 365 Connectors and Enterprise Search for Team and Enterprise accounts. https://t.co/jcMJG77oXc",
        "Anthropic launches their first Haiku model in 11 months - Claude 4.5 Haiku jumps 35 points in Artificial Analysis Intelligence Index to become relevant again\n\nClaude 4.5 Haiku is 3x cheaper per token than Claude 4.5 Sonnet. Running the Artificial Analysis Intelligence Index costs $262 with Haiku vs. $817 with Sonnet (~3x more) - full cost breakdown in the thread below.\n\nThere is a stronger case for 4.5 Haiku‚Äôs intelligence/cost positioning than 3.5 Haiku, but there is a competitive field of cheaper alternatives with similar intelligence that may make more sense for developers without a reason to need a Claude model specifically - including gpt-oss-120b (reasoning high, ~$75) and Grok 4 Fast (~$40). Claude 4.5 Haiku is the most cost-effective way to access ‚ÄòClaude‚Äô but is not the most cost effective model for its level of intelligence.\n\nKey benchmarking results:\n‚û§üß† Model Intelligence: In reasoning mode, Claude 4.5 Haiku scores 55 on the Artificial Analysis Intelligence Index. This is 8 points lower than Claude 4.5 Sonnet (Thinking) and 4 points lower than Claude 4.1 Opus (Thinking). Claude 4.5 Haiku (Thinking) places marginally ahead of Gemini 2.5 Flash (Reasoning, 54) but behind other reasoning models such as Qwen3 235B 2507 (57), DeepSeek V3.2 Exp (57), and GLM 4.6 (56)\n‚û§üìà Intelligence Uplift: Anthropic released Claude 3.5 Haiku in November 2024, ~11 months before the release of Claude 4.5 Haiku. Claude 4.5 Haiku is a significant improvement in intelligence compared to Claude 3.5 Haiku, scoring 67% on GPQA Diamond in reasoning mode (compared to 41% for Claude 3.5 Haiku)\n‚û§‚öôÔ∏è Notable Strengths: In reasonign mode, Claude 4.5 Haiku performs well in long-context reasoning (70% on AA-LCR, behind only GPT-5 High) and coding (43%, matching GPT-5 High and Gemini 2.5 Pro)\n‚û§‚ö° Non-Reasoning Performance: In non-reasoning mode, Claude 4.5 Haiku scores 42 on the Artificial Analysis Intelligence Index. This places the model in line with GPT-5 (minimal, 43) but behind Gemini 2.5 Flash (non-reasoning, 47)\n‚û§üí≤ Pricing: Claude 4.5 Haiku is priced at $1/$5 per 1M input/output tokens, which makes it 3x cheaper compared to Claude 4.5 Sonnet (priced at $3/$15 per 1M input/output tokens)\n‚û§‚öôÔ∏è Token Efficiency: Anthropic‚Äôs Claude models continue to be more token-efficient than all other reasoning models. For Claude 4.5 Haiku (Thinking) -evaluated with a maximum reasoning budget of 64k tokens - we see the model use 39M output tokens to run the Artificial Analysis Intelligence Index. Its token usage is lower than Claude 4.5 Sonnet (42M) but higher than Claude 4.1 Opus (30M) in thinking mode\n\nKey model details:\n\n‚û§üìè¬†Context Window: 200K tokens. This is equivalent to Claude 4.5 Sonnet\n‚û§üåê¬†Availability: Claude 4.5 Haiku is available via Anthropic‚Äòs API, Google Vertex and Amazon Bedrock. Claude 4.5 Haiku is also available via Claude, and Claude Code"
      ]
    },
    "GPT-5": {
      "mention_count": 4,
      "first_mentioned": "Thu Oct 16 02:29:47 +0000 2025",
      "discoverers": [
        {
          "kol": "ArtificialAnlys",
          "rank": 20
        },
        {
          "kol": "Angaisb_",
          "rank": 24
        },
        {
          "kol": "Angaisb_",
          "rank": 24
        },
        {
          "kol": "deredleritt3r",
          "rank": 154
        }
      ],
      "sample_tweets": [
        "Anthropic launches their first Haiku model in 11 months - Claude 4.5 Haiku jumps 35 points in Artificial Analysis Intelligence Index to become relevant again\n\nClaude 4.5 Haiku is 3x cheaper per token than Claude 4.5 Sonnet. Running the Artificial Analysis Intelligence Index costs $262 with Haiku vs. $817 with Sonnet (~3x more) - full cost breakdown in the thread below.\n\nThere is a stronger case for 4.5 Haiku‚Äôs intelligence/cost positioning than 3.5 Haiku, but there is a competitive field of cheaper alternatives with similar intelligence that may make more sense for developers without a reason to need a Claude model specifically - including gpt-oss-120b (reasoning high, ~$75) and Grok 4 Fast (~$40). Claude 4.5 Haiku is the most cost-effective way to access ‚ÄòClaude‚Äô but is not the most cost effective model for its level of intelligence.\n\nKey benchmarking results:\n‚û§üß† Model Intelligence: In reasoning mode, Claude 4.5 Haiku scores 55 on the Artificial Analysis Intelligence Index. This is 8 points lower than Claude 4.5 Sonnet (Thinking) and 4 points lower than Claude 4.1 Opus (Thinking). Claude 4.5 Haiku (Thinking) places marginally ahead of Gemini 2.5 Flash (Reasoning, 54) but behind other reasoning models such as Qwen3 235B 2507 (57), DeepSeek V3.2 Exp (57), and GLM 4.6 (56)\n‚û§üìà Intelligence Uplift: Anthropic released Claude 3.5 Haiku in November 2024, ~11 months before the release of Claude 4.5 Haiku. Claude 4.5 Haiku is a significant improvement in intelligence compared to Claude 3.5 Haiku, scoring 67% on GPQA Diamond in reasoning mode (compared to 41% for Claude 3.5 Haiku)\n‚û§‚öôÔ∏è Notable Strengths: In reasonign mode, Claude 4.5 Haiku performs well in long-context reasoning (70% on AA-LCR, behind only GPT-5 High) and coding (43%, matching GPT-5 High and Gemini 2.5 Pro)\n‚û§‚ö° Non-Reasoning Performance: In non-reasoning mode, Claude 4.5 Haiku scores 42 on the Artificial Analysis Intelligence Index. This places the model in line with GPT-5 (minimal, 43) but behind Gemini 2.5 Flash (non-reasoning, 47)\n‚û§üí≤ Pricing: Claude 4.5 Haiku is priced at $1/$5 per 1M input/output tokens, which makes it 3x cheaper compared to Claude 4.5 Sonnet (priced at $3/$15 per 1M input/output tokens)\n‚û§‚öôÔ∏è Token Efficiency: Anthropic‚Äôs Claude models continue to be more token-efficient than all other reasoning models. For Claude 4.5 Haiku (Thinking) -evaluated with a maximum reasoning budget of 64k tokens - we see the model use 39M output tokens to run the Artificial Analysis Intelligence Index. Its token usage is lower than Claude 4.5 Sonnet (42M) but higher than Claude 4.1 Opus (30M) in thinking mode\n\nKey model details:\n\n‚û§üìè¬†Context Window: 200K tokens. This is equivalent to Claude 4.5 Sonnet\n‚û§üåê¬†Availability: Claude 4.5 Haiku is available via Anthropic‚Äòs API, Google Vertex and Amazon Bedrock. Claude 4.5 Haiku is also available via Claude, and Claude Code",
        "@chatgpt21 Gemini 3.0 Pro will be a new baseline and they can't just wait until February to compete with it (imo)\n\nAlso, at least for me GPT-5 wasn't the jump we expected, OpenAI knew that, but GPT-5 was meant to be used by all users, not only paid users\n\nMaybe they were already working on this much better model but they've been trying to optimize compute and wait for more GPUs"
      ]
    },
    "GoogleAIStudio": {
      "mention_count": 4,
      "first_mentioned": "Sat Oct 11 07:19:53 +0000 2025",
      "discoverers": [
        {
          "kol": "OfficialLoganK",
          "rank": 33
        },
        {
          "kol": "_philschmid",
          "rank": 52
        },
        {
          "kol": "_philschmid",
          "rank": 52
        },
        {
          "kol": "multimodalart",
          "rank": 83
        }
      ],
      "sample_tweets": [
        "@alex_barashkov @GoogleAIStudio we are fixing this, a totally new billing experience will land in Jan :) long long time coming",
        "New \"one playground\" in @GoogleAIStudio! Consolidates all Gemini API models, text generation, image, audio or live API into a single playground interface! üòÆ‚Äçüí®\n\nGive it a try and let us know what you think. https://t.co/2wEFSvfkug"
      ]
    },
    "Cursor": {
      "mention_count": 4,
      "first_mentioned": "Fri Oct 17 02:55:20 +0000 2025",
      "discoverers": [
        {
          "kol": "maccaw",
          "rank": 97
        },
        {
          "kol": "maccaw",
          "rank": 97
        },
        {
          "kol": "rileybrown_ai",
          "rank": 123
        },
        {
          "kol": "Prathkum",
          "rank": 163
        }
      ],
      "sample_tweets": [
        "In general, you want to get out of the way and let the AI do as much as possible. If you are in the loop copying and pasting, then you're just going to slow it down and potentially not give the AI enough context.\n\nCursor has a new \"plan\" feature that is extremely helpful. I use that as the first step when building up the initial plan. I then have a custom action to review that plan. I get much better results this way.\n\nPlan mode: https://t.co/4naKLxvlry\n\nPrompt here: https://t.co/DnEzxou1PL",
        "The best models in my experience right now are Claude Sonnet 4.5 and a new undisclosed model called `cheetah` on Cursor, which is next-level quick."
      ]
    },
    "Lovable": {
      "mention_count": 4,
      "first_mentioned": "Fri Oct 17 02:55:20 +0000 2025",
      "discoverers": [
        {
          "kol": "antonosika",
          "rank": 119
        },
        {
          "kol": "antonosika",
          "rank": 119
        },
        {
          "kol": "antonosika",
          "rank": 119
        },
        {
          "kol": "rileybrown_ai",
          "rank": 123
        }
      ],
      "sample_tweets": [
        "That meant Lovable started growing much faster.\n\nAnd every time a user needed a backend, a new database was spun up automatically.\n\n//3",
        "The new Lovable Cloud takes care of all backend automatically and lets you add AI functionality without API keys or separate billing.\n\nPeople love it. The launch went viral, and the value people get from Lovable  jumped (measured by conversion rate from free to paid user).\n\n//2"
      ]
    },
    "VS Code": {
      "mention_count": 3,
      "first_mentioned": "Thu Oct 16 18:15:32 +0000 2025",
      "discoverers": [
        {
          "kol": "code",
          "rank": 4
        },
        {
          "kol": "Prathkum",
          "rank": 163
        },
        {
          "kol": "DeepLearningAI",
          "rank": 184
        }
      ],
      "sample_tweets": [
        "@ProgressSW In Peru, local communities hosted 3 VS Code Dev Days in Lima, featuring talks and hands-on sessions for developers to learn and practice new skills. üíª‚ú® https://t.co/XcWsLhX25Q",
        "Frontend developers, you are not ready for this.\n\nKombai is a new VS Code or Cursor extension that converts your Figma designs directly into production-ready frontend code.\n\nActual clean and readable code you would ship.\n\n@Kombaico is a highly fine-tuned agent, resulting in beating general LLMs like Claude 4 or Gemini 2.5 Pro.\n\nIt can:\n\n‚Ä¢ turn a Figma design or screenshot into full React code\n‚Ä¢ build individual components or entire pages\n‚Ä¢ refactor your existing UI\n‚Ä¢ follow your design system and CSS architecture\n‚Ä¢ generate code that‚Äôs actually review-ready\n\nDownload it here: https://t.co/nh0LYTm3JV\n\nNext, I am going to convince my manager to opt for this in our actual office workflow.\n\nAppreciate the Kombai team for collaborating with me on this deep dive."
      ]
    },
    "GPT-2": {
      "mention_count": 2,
      "first_mentioned": "Thu Oct 16 00:14:42 +0000 2025",
      "discoverers": [
        {
          "kol": "karpathy",
          "rank": 7
        },
        {
          "kol": "scaling01",
          "rank": 8
        }
      ],
      "sample_tweets": [
        "nanochat d32, i.e. the depth 32 version that I specced for $1000, up from $100 has finished training after ~33 hours, and looks good. All the metrics go up quite a bit across pretraining, SFT and RL. CORE score of 0.31 is now well above GPT-2 at ~0.26. GSM8K went ~8% -> ~20%, etc. So that's encouraging.\n\nThe model is pretty fun to talk to, but judging from some early interactions I think people have a little bit too much expectation for these micro models. There is a reason that frontier LLM labs raise billions to train their models. nanochat models cost $100 - $1000 to train from scratch. The $100 nanochat is 1/1000th the size of GPT-3 in parameters, which came out 5 years ago. So I urge some perspective. Talking to micro models you have to imagine you're talking to a kindergarten child. They say cute things, wrong things, they are a bit confused, a bit naive, sometimes a little non-sensical, they hallucinate a ton (but it's amusing), etc.\n\nFull detail/report on this run is here:\nhttps://t.co/nWbfKOZLIg\nAnd I pushed the new script run1000 sh to the nanochat repo if anyone would like to reproduce. Totally understand if you'd like to spend $1000 on something else :D\n\nIf you like, I am currently hosting the model so you can talk to it on a webchat as you'd talk to ChatGPT. I'm not going to post the URL here because I'm afraid it will get crushed. You'll have to look for it if you care enough. I'm also attaching a few funny conversations I had with the model earlier into the image, just to give a sense.\n\nNext up, I am going to do one pass of tuning and optimizing the training throughput, then maybe return back to scaling and maybe training the next tier of a bigger model.",
        "I was wondering if I should start a GregTech New Horizons world (hardest Minecraft modpack), since my silly ass forgot to back up my old Minecraft worlds, or learn how to implement GPT-2 from scratch in pytorch.\n\nNaturally, I watched another video about the modpack first. The guy in the video talked about his motivation, goals and how to plan, since the modpack takes a few thousand hours to complete.\nBut all I could think of was that he was actually giving insanely good advice for life.\n\nIt's why I ended up doing the GPT-2 stuff instead. Because GTNH would ultimately just be a quicker way to feel like I achieved something. But the complexity of the game and the time you need to invest in it makes you realize that life is also a game.\nJust a more difficult one with even sparser rewards. So why not go the extra inch and get some useful real world achievements?\n\nImagine what you could achieve with a few thousand hours of real world grinding.\n\nhttps://t.co/gchJA6M9ad"
      ]
    },
    "Copilot": {
      "mention_count": 2,
      "first_mentioned": "Thu Oct 16 19:55:57 +0000 2025",
      "discoverers": [
        {
          "kol": "satyanadella",
          "rank": 18
        },
        {
          "kol": "itsPaulAi",
          "rank": 45
        }
      ],
      "sample_tweets": [
        "This is super useful! With new Formula Completions in Excel, just type \"=\" and Copilot proactively suggests a formula, based on the context of your sheet. Here's a great example. https://t.co/elkGzHjZTW",
        "Wow Microsoft just announced Copilot Actions for local files ü§Ø\n\nYou can basically ask Copilot to perform any task on your machine autonomously. Yes.\n\n- Open Copilot in Windows\n- Assign a goal in natural language\n- Copilot launches a contained environment\n- It works autonomously for you\n\nCopilot can use both your desktop and any web app.\n\nAnd you can take back control at any time.\n\nThis allows you to do whatever you want while the AI performs your tasks... or even do nothing at all.\n\nThe entire OS becomes agentic. Impressive."
      ]
    },
    "chatgpt21": {
      "mention_count": 2,
      "first_mentioned": "Thu Oct 16 21:21:14 +0000 2025",
      "discoverers": [
        {
          "kol": "Angaisb_",
          "rank": 24
        },
        {
          "kol": "Angaisb_",
          "rank": 24
        }
      ],
      "sample_tweets": [
        "@chatgpt21 Gemini 3.0 Pro will be a new baseline and they can't just wait until February to compete with it (imo)\n\nAlso, at least for me GPT-5 wasn't the jump we expected, OpenAI knew that, but GPT-5 was meant to be used by all users, not only paid users\n\nMaybe they were already working on this much better model but they've been trying to optimize compute and wait for more GPUs",
        "@chatgpt21 Well, we know:\n- They have a model that got gold on the IMO\n- OpenAI releases models every few months\n- They fixed naming with GPT-5, so it'd be dumb to make new names again and have another mix of models\n- OpenAI employees saying GPT-5 is basically o3.1\n\nIn my opinion everything points towards GPT-6 this year"
      ]
    },
    "GPT-6": {
      "mention_count": 2,
      "first_mentioned": "Thu Oct 16 21:10:53 +0000 2025",
      "discoverers": [
        {
          "kol": "Angaisb_",
          "rank": 24
        },
        {
          "kol": "deredleritt3r",
          "rank": 154
        }
      ],
      "sample_tweets": [
        "@chatgpt21 Well, we know:\n- They have a model that got gold on the IMO\n- OpenAI releases models every few months\n- They fixed naming with GPT-5, so it'd be dumb to make new names again and have another mix of models\n- OpenAI employees saying GPT-5 is basically o3.1\n\nIn my opinion everything points towards GPT-6 this year",
        "@k_kohlbrenner @btibor91 @testingcatalog @OpenAI @ChatGPTapp OpenAI has a number of model checkpoints available internally, and in theory, any of those checkpoints could be released at any time under the name \"GPT-6\". \n\nI'm skeptical that this will actually happen this year unless there's been some kind of algorithmic breakthrough that actually makes this \"GPT-6\" a step change from current publicly available models."
      ]
    },
    "drops": {
      "mention_count": 2,
      "first_mentioned": "Fri Oct 17 10:30:00 +0000 2025",
      "discoverers": [
        {
          "kol": "_philschmid",
          "rank": 52
        },
        {
          "kol": "MarioNawfal",
          "rank": 131
        }
      ],
      "sample_tweets": [
        "Here is an example of the new Guided Video Generation Prompt:\n\nThe video starts with a fast, dynamic drone-style shot flying low over turquoise water, rushing rapidly towards the sandy beach and palm trees. The sound is a loud, energetic crash of waves mixed with a 'whoosh' of movement. There are no subtitles on the screen.\n\nA sudden, fast whip-pan camera move lands perfectly on the giant, mouth-watering burger, which is now sitting on a table right on the sunny beach. High-energy tropical bass music drops instantly. The camera zooms in rapidly on the juicy patty, fresh green topping, and glistening onions. An energetic, hyped voiceover shouts, \"Crash into flavor! The new Island Burger is here, only at Veo!\" A loud sizzle sound effect plays over the music.\n\nSmash cut to a vibrant background featuring a large, stylized \"V\" logo. Text below reads \"Made with Veo\" as the iconic jingle plays loudly.",
        "üö®12 HOUR NEWS RECAP\n\n1.‚Å† Trump said Putin called to congratulate him on Middle East peace and hinted it could lead to an end of the Ukraine war. The pair agreed to meet in Hungary, aiming to negotiate an end to the war.\n\n2.‚Å† VP Vance said Russia and Ukraine are still not close enough to get a deal: \"For all of our work - and we're going to keep on working at it - the Russians and the Ukrainians are just not at the point where they can make a deal. I do think that we will eventually get there.\"\n\n3.‚Å† India is cutting Russian oil purchases in half following trade talks with the White House, according to a senior US official. Catch the fine print: the cuts won't show up in official data until December or January since refiners already locked in November cargoes. \n\n4.‚Å† Venezuelan officials floated a deal: Maduro would step down‚Ä¶ in 3 years, handing power to his VP Delcy Rodriguez (who wouldn‚Äôt run again). The White House shut it down, calling Maduro‚Äôs regime illegitimate and accusing it of running a narco-state.\n\n5.‚Å† Israel says Hamas can return a ‚Äúdouble-digit‚Äù number of deceased hostages - but isn‚Äôt. Only 9 bodies have been returned under the U.S-brokered deal, while 19 remain. Israel now considers this a ‚Äúfundamental breach‚Äù of the ceasefire agreement.\n\n6.‚Å† Kai Trump launched her YouTube era with ‚Äú1 on 1 with Kai‚Äù - featuring 18 holes, drone shots, hot mics, and Grandpa... aka ‚Äú45 and 47.‚Äù She drops bombs off the tee, breaks down her 60¬∞ wedge strategy, and casually roasts his fairway bunker game.\n\n7.‚Å† A Polish court will decide whether to extradite Ukrainian diver Volodymyr Z. to Germany over alleged involvement in the 2022 Nord Stream pipeline explosions. Prime Minister Donald Tusk opposes the transfer, saying it‚Äôs not in Poland‚Äôs interest.\n\n8.‚Å† Ukrainian drones struck the Gvardeyskoye fuel depot in Russian-occupied Crimea, setting the facility ablaze. The depot supplied fuel to a large portion of the peninsula, disrupting one of Moscow‚Äôs key supply routes in the region. \n\n9.‚Å† Federal prosecutors charged Los Angeles developers Steven Taylor and Cody Holmes for allegedly stealing millions meant for homeless housing projects. Taylor flipped a Cheviot Hills property to a nonprofit tied to former state senator Kevin Murray for a $16 million profit. Holmes, meanwhile, used $2.2 million in public housing funds to pay luxury credit card bills. \n\n10.‚Å† NYC mayor hopeful Mamdani blasted Trump for threatening to deploy the National Guard to New York: ‚ÄúI agree with Police Commissioner Tish that we do not need the National Guard here in New York City. What New Yorkers need is a mayor who can stand up to Donald Trump and actually deliver on safety.\""
      ]
    },
    "AnthropicAI": {
      "mention_count": 2,
      "first_mentioned": "Wed Oct 15 18:10:25 +0000 2025",
      "discoverers": [
        {
          "kol": "GoogleCloudTech",
          "rank": 71
        },
        {
          "kol": "arena",
          "rank": 114
        }
      ],
      "sample_tweets": [
        "New model üö®Announcing @claudeai Haiku 4.5 on Vertex AI!\n\nClaude Haiku 4.5 offers a great combination of performance, price, and speed among @AnthropicAI models‚Äîdesigned for parallelized execution, sub-agents, and powering free-tier user experiences ‚Üí https://t.co/1VKeuGWET8 https://t.co/mGy2lB4KXH",
        "üö® New Model Update!\n\nClaude Haiku 4.5 is in the Arena!\n@AnthropicAI's  latest small model is now available for Text and WebDev ‚ö°Ô∏è\n\nCome test it out and tell us what you think. Your votes drive the leaderboards! https://t.co/qA0uwyKqEm"
      ]
    },
    "drop": {
      "mention_count": 2,
      "first_mentioned": "Mon Oct 13 20:08:44 +0000 2025",
      "discoverers": [
        {
          "kol": "arena",
          "rank": 114
        },
        {
          "kol": "karinanguyen_",
          "rank": 204
        }
      ],
      "sample_tweets": [
        "üö®New model drop into the Top 10!\nüñºÔ∏è @MicrosoftAI just entered the Image Arena with MAI-Image-1.\n\nCommunity votes are already rolling in, and MAI-Image-1 has broken into the Top 10. It‚Äôs currently ranked #9, tied with Seedream 3! \n\nMAI-Image-1 is now live in Direct Chat for early access on LMArena.",
        "The first drop is on Oct 22, 2025\nSign up to be notified: https://t.co/bWGaAjxC44\n\nProceeds from this collection will fund grants for emerging artists and creatives exploring new forms of creation. https://t.co/yjozEUHFC5"
      ]
    },
    "vibecodeapp": {
      "mention_count": 2,
      "first_mentioned": "Fri Oct 17 02:55:20 +0000 2025",
      "discoverers": [
        {
          "kol": "rileybrown_ai",
          "rank": 123
        },
        {
          "kol": "rileybrown_ai",
          "rank": 123
        }
      ],
      "sample_tweets": [
        "Do you realize the entire mobile app industry is going to be flipped onto its head? \n\nI created an instagram, TikTok, YT, transcript scraper Mobile App...\n\nIn 3 prompts, from my phone, with:\n\nAuth, DB, Storage, API's (Supadata, Apify) \n\nOn the @vibecodeapp (v2, coming soon)\n\nSoon we will release a new interface for vibe coding on the phone, that gives the user FULL control over their app. \n\nPower of Cursor, Ease of Lovable, Feels like Capcut.",
        "I use 12-15 tools weekly on my macbook pro that help me grow to over 1.4M followers across social media, and our company to 7 figures ARR. \n\nI'm going to be talking about all of them in my first official live stream on YouTube, X, and Twitch, from the @vibecodeapp HQ in SF.\n\nLive Stream on YouTube Today 2:30 - 5:30PT\n\nWill talk about the stack\nAI News (Veo + Haiku) \nUpdates on the Startup\nPlan for Streaming\nAnd QandA.\n\nMaybe guest appearances from @anshnanda_ and @zzulali but they are working on something INSANE so idk."
      ]
    },
    "JDVance": {
      "mention_count": 2,
      "first_mentioned": "Fri Oct 17 09:00:02 +0000 2025",
      "discoverers": [
        {
          "kol": "MarioNawfal",
          "rank": 131
        },
        {
          "kol": "MarioNawfal",
          "rank": 131
        }
      ],
      "sample_tweets": [
        "üá∫üá∏ JD VANCE: ‚ÄúAI FOR FINDING NEW CANCER TREATMENT - THAT'S GREAT. AI FOR CREATING WEIRD PORN - THAT'S BAD‚Äù\n\n\"You asked if it's good or bad - is it going to help us or hurt us? \n\nThe answer is probably both, and we should be trying to maximize as much of the good and minimize as much of the bad.\n\nResearchers used AI to identify a new cancer drug pathway that nobody had ever come up with, and they're starting to see evidence it could be a promising way to treat certain types of cancer. \n\nThat's what we want AI to do - unlock new therapeutics so that people can live longer, healthier lives.\n\nAt the same time, I saw an announcement that they‚Äôre going to start using AI to introduce erotica and porn. \n\nIf AI is helping us find new cures for new diseases, that‚Äôs great. If it‚Äôs helping us come up with increasingly weird porn, that‚Äôs bad.\"\n\nSource: @JDVance, NEWSMAX,¬†@clashreport",
        "üá∫üá∏ JD VANCE: ‚ÄúRUSSIA AND UKRAINE ARE NOT YET AT THE POINT OF A DEAL‚Äù\n\n\"For all of our work - and we're going to keep on working at it - the Russians and the Ukrainians are just not at the point where they can make a deal.\n\nI do think that we will eventually get there.\"\n\nSource: @JDVance, NEWSMAX, @clashreport"
      ]
    }
  },
  "top_kols": {
    "karpathy": 20,
    "freeCodeCamp": 20,
    "verge": 20,
    "jaguring1": 19,
    "unusual_whales": 19,
    "emollick": 18,
    "masahirochaen": 18,
    "penpenguin2023": 18,
    "OfficialLoganK": 17,
    "adonis_singh": 17,
    "madonomori": 17,
    "ArtificialAnlys": 16,
    "btibor91": 16,
    "alexalbert__": 16,
    "ctgptlb": 16,
    "DotCSV": 15,
    "satyanadella": 15,
    "_philschmid": 15,
    "waitin4agi_": 15,
    "itmedia_news": 15
  },
  "daily_distribution": {
    "16 13:20:19": 1,
    "15 16:11:56": 1,
    "15 12:53:00": 1,
    "15 12:41:19": 1,
    "15 12:38:46": 1,
    "15 12:08:57": 1,
    "15 12:07:09": 1,
    "15 12:06:36": 1,
    "13 23:31:48": 1,
    "13 19:11:12": 1,
    "13 18:43:34": 1,
    "13 17:43:49": 1,
    "12 17:01:47": 1,
    "12 16:58:41": 1,
    "11 14:59:09": 1,
    "17 11:26:31": 1,
    "17 10:13:03": 2,
    "17 08:58:07": 1,
    "17 08:58:04": 1,
    "17 08:14:20": 1,
    "16 23:34:13": 1,
    "16 20:58:44": 1,
    "16 20:58:07": 1,
    "16 20:54:14": 1,
    "16 20:54:11": 1,
    "16 20:54:08": 1,
    "16 22:05:09": 1,
    "16 22:05:08": 1,
    "16 22:05:07": 1,
    "16 18:15:32": 3,
    "16 18:15:29": 2,
    "16 15:06:12": 1,
    "15 19:04:52": 1,
    "14 17:24:07": 1,
    "13 16:15:39": 1,
    "10 21:59:01": 1,
    "17 09:50:00": 1,
    "17 07:35:33": 1,
    "17 05:00:00": 1,
    "17 03:11:56": 1,
    "17 02:40:00": 1,
    "17 00:10:00": 1,
    "16 21:50:00": 1,
    "13 10:00:01": 1,
    "13 02:00:00": 1,
    "12 10:00:01": 1,
    "11 20:00:01": 1,
    "11 17:30:00": 1,
    "11 10:00:02": 1,
    "17 02:18:08": 1,
    "16 14:47:51": 2,
    "16 02:57:13": 1,
    "16 02:50:45": 1,
    "16 02:50:27": 1,
    "16 02:47:08": 1,
    "16 00:14:42": 1,
    "15 16:51:01": 1,
    "14 15:00:58": 1,
    "13 21:22:40": 1,
    "13 17:21:39": 1,
    "13 16:32:15": 1,
    "13 16:29:49": 1,
    "13 16:23:01": 1,
    "13 15:49:50": 1,
    "13 15:48:04": 1,
    "13 15:37:33": 1,
    "13 15:27:55": 1,
    "13 15:16:54": 2,
    "16 20:07:55": 1,
    "16 10:10:40": 1,
    "16 01:49:02": 1,
    "16 01:41:42": 1,
    "16 00:53:56": 1,
    "16 00:53:54": 1,
    "16 00:43:58": 1,
    "15 21:17:51": 1,
    "15 20:22:35": 1,
    "15 19:51:58": 1,
    "15 19:51:13": 1,
    "15 19:49:02": 1,
    "17 07:23:33": 1,
    "17 02:17:39": 1,
    "17 00:37:49": 1,
    "16 16:49:42": 1,
    "16 16:32:27": 1,
    "16 16:24:20": 1,
    "16 16:00:45": 1,
    "16 11:41:35": 1,
    "16 03:50:18": 1,
    "16 01:06:17": 1,
    "16 17:02:09": 1,
    "14 17:49:25": 1,
    "13 19:25:15": 1,
    "13 15:02:01": 1,
    "17 01:11:55": 1,
    "16 15:12:36": 1,
    "17 09:22:52": 1,
    "17 08:01:36": 1,
    "16 12:23:41": 1,
    "16 06:23:38": 1,
    "16 19:58:51": 1,
    "16 18:10:19": 1,
    "16 15:11:13": 1,
    "16 14:58:05": 1,
    "16 14:19:55": 1,
    "16 14:15:08": 1,
    "16 13:55:50": 1,
    "16 12:28:05": 1,
    "17 05:06:05": 1,
    "17 05:05:47": 2,
    "17 05:05:46": 2,
    "17 05:05:45": 2,
    "17 05:05:44": 1,
    "16 14:09:33": 2,
    "16 13:08:25": 1,
    "16 13:08:24": 1,
    "15 22:46:41": 1,
    "15 20:53:44": 2,
    "14 19:03:08": 2,
    "13 17:08:17": 1,
    "12 20:57:51": 1,
    "12 20:57:50": 2,
    "12 20:57:49": 1,
    "12 20:57:48": 1,
    "16 21:54:19": 1,
    "16 21:47:39": 1,
    "16 21:45:00": 1,
    "16 20:47:23": 1,
    "16 20:44:14": 1,
    "16 19:57:32": 1,
    "16 19:46:59": 1,
    "16 19:35:33": 1,
    "16 19:32:27": 1,
    "16 19:24:00": 1,
    "16 16:48:04": 1,
    "16 16:42:37": 1,
    "16 19:04:02": 1,
    "16 19:03:42": 1,
    "16 18:30:00": 2,
    "16 18:29:55": 2,
    "16 03:17:59": 1,
    "16 03:17:58": 1,
    "16 03:17:57": 2,
    "16 03:17:56": 2,
    "16 03:17:55": 1,
    "15 20:39:22": 1,
    "15 20:39:21": 3,
    "15 17:37:10": 1,
    "17 03:17:37": 1,
    "17 03:05:27": 1,
    "17 02:45:53": 1,
    "17 02:35:18": 1,
    "17 02:22:30": 1,
    "17 02:12:07": 1,
    "17 02:06:00": 1,
    "17 01:48:32": 1,
    "17 01:28:57": 1,
    "17 01:26:12": 1,
    "17 01:24:00": 1,
    "17 01:07:24": 1,
    "17 00:25:26": 1,
    "16 23:33:46": 1,
    "16 23:30:59": 1,
    "16 18:14:22": 1,
    "16 18:00:33": 1,
    "16 17:40:06": 1,
    "17 09:07:11": 1,
    "17 08:35:24": 1,
    "15 13:38:53": 1,
    "13 21:27:41": 1,
    "13 11:13:37": 1,
    "13 01:47:04": 1,
    "16 23:29:33": 1,
    "16 22:45:37": 1,
    "16 21:45:37": 1,
    "16 21:34:15": 1,
    "16 21:21:14": 1,
    "16 20:56:57": 1,
    "16 16:37:44": 1,
    "16 20:58:27": 1,
    "16 20:58:20": 1,
    "16 18:44:46": 1,
    "16 18:15:53": 1,
    "16 16:40:50": 1,
    "16 16:40:47": 1,
    "16 16:40:44": 1,
    "16 14:59:01": 1,
    "16 10:56:16": 1,
    "16 10:56:13": 1,
    "16 08:20:18": 1,
    "16 08:20:15": 1,
    "16 08:20:12": 1,
    "16 06:34:56": 1,
    "16 06:34:53": 1,
    "16 06:29:34": 1,
    "17 11:00:56": 1,
    "17 10:04:20": 1,
    "17 06:30:25": 1,
    "17 06:00:45": 1,
    "17 05:15:20": 1,
    "17 04:00:39": 1,
    "17 03:30:19": 1,
    "17 03:13:19": 1,
    "17 03:05:19": 1,
    "17 03:00:41": 1,
    "17 02:54:21": 1,
    "17 02:50:19": 1,
    "17 02:45:20": 1,
    "17 02:15:22": 1,
    "16 21:35:14": 1,
    "16 14:18:38": 1,
    "15 18:38:57": 1,
    "15 17:00:17": 1,
    "16 17:54:45": 1,
    "16 17:51:39": 1,
    "16 08:23:16": 1,
    "16 07:55:51": 1,
    "16 07:51:35": 1,
    "16 07:04:48": 1,
    "16 04:15:37": 1,
    "16 02:51:02": 1,
    "16 02:26:53": 1,
    "15 23:12:20": 1,
    "14 00:31:07": 1,
    "13 16:40:14": 1,
    "13 14:49:12": 1,
    "13 14:48:22": 1,
    "13 13:33:38": 1,
    "11 14:51:58": 1,
    "11 14:43:28": 1,
    "11 14:40:09": 1,
    "11 14:37:18": 1,
    "16 16:43:36": 1,
    "16 16:29:37": 1,
    "16 16:27:35": 1,
    "16 16:23:55": 1,
    "16 13:52:06": 1,
    "16 13:25:14": 1,
    "16 19:19:14": 1,
    "16 13:51:32": 1,
    "16 08:18:46": 1,
    "15 19:00:59": 1,
    "15 15:00:59": 1,
    "15 14:41:54": 1,
    "17 03:31:26": 1,
    "17 02:51:54": 1,
    "17 02:49:53": 1,
    "16 23:48:05": 1,
    "16 23:09:31": 1,
    "16 22:24:14": 1,
    "16 22:16:01": 1,
    "16 22:14:10": 1,
    "16 22:13:30": 1,
    "16 22:02:06": 2,
    "16 22:01:38": 1,
    "16 18:56:03": 1,
    "16 16:47:55": 1,
    "16 16:47:11": 1,
    "16 16:39:04": 1,
    "16 16:35:35": 1,
    "16 01:48:44": 1,
    "15 23:49:58": 1,
    "15 17:49:22": 1,
    "15 16:31:10": 1,
    "15 16:07:01": 1,
    "15 16:06:15": 1,
    "15 01:42:55": 1,
    "14 16:42:43": 1,
    "14 16:41:29": 1,
    "14 16:40:34": 1,
    "14 16:39:38": 1,
    "13 22:54:39": 1,
    "17 08:36:03": 2,
    "17 08:35:39": 1,
    "17 08:35:12": 1,
    "16 09:59:09": 1,
    "16 09:56:22": 1,
    "16 09:47:27": 1,
    "16 06:12:42": 1,
    "16 05:32:19": 1,
    "16 05:19:55": 1,
    "16 05:12:58": 1,
    "17 11:37:00": 1,
    "17 11:17:00": 1,
    "17 11:02:10": 1,
    "17 10:37:56": 1,
    "17 10:33:50": 1,
    "17 05:22:30": 1,
    "17 02:58:00": 1,
    "17 02:31:00": 1,
    "17 01:58:00": 1,
    "17 01:31:00": 1,
    "17 00:58:00": 1,
    "17 00:31:00": 1,
    "16 23:58:00": 1,
    "16 23:31:00": 1,
    "16 22:58:00": 1,
    "16 22:31:00": 1,
    "16 21:58:00": 1,
    "16 21:31:00": 1,
    "16 20:58:00": 1,
    "16 03:21:05": 1,
    "13 02:12:30": 1,
    "17 05:11:06": 1,
    "17 01:45:11": 1,
    "17 09:44:04": 1,
    "17 09:23:28": 1,
    "17 09:17:21": 1,
    "17 11:30:05": 1,
    "17 09:30:10": 1,
    "17 07:00:07": 1,
    "17 06:00:09": 1,
    "17 03:00:17": 1,
    "16 23:30:06": 1,
    "16 23:06:28": 1,
    "16 21:47:01": 1,
    "17 09:00:33": 1,
    "17 06:21:07": 1,
    "17 01:22:35": 1,
    "16 23:16:19": 1,
    "16 22:36:03": 1,
    "16 19:53:50": 1,
    "16 21:53:30": 1,
    "16 19:55:57": 1,
    "12 07:02:25": 1,
    "11 21:50:02": 1,
    "11 21:47:41": 1,
    "17 11:08:56": 1,
    "17 11:06:40": 1,
    "17 11:05:41": 1,
    "17 11:03:54": 1,
    "17 06:56:58": 1,
    "17 05:52:46": 1,
    "17 04:03:17": 1,
    "17 01:02:29": 1,
    "16 23:59:17": 1,
    "16 23:58:58": 1,
    "16 22:26:27": 1,
    "16 22:18:29": 1,
    "16 19:04:45": 1,
    "17 02:33:30": 1,
    "13 22:36:27": 1,
    "13 06:05:07": 1,
    "13 06:04:51": 1,
    "11 01:23:36": 1,
    "16 22:54:46": 1,
    "16 22:53:10": 1,
    "16 16:39:01": 1,
    "16 02:09:00": 1,
    "15 23:31:39": 1,
    "15 16:44:05": 1,
    "15 09:22:39": 1,
    "12 23:03:57": 1,
    "12 23:03:48": 1,
    "12 23:03:27": 1,
    "12 23:02:32": 1,
    "12 23:02:31": 1,
    "17 00:16:01": 1,
    "16 22:02:13": 1,
    "16 22:02:12": 1,
    "16 22:02:10": 1,
    "16 22:02:08": 1,
    "16 18:11:47": 1,
    "16 10:38:55": 1,
    "16 06:27:02": 1,
    "16 06:26:19": 1,
    "16 01:15:24": 1,
    "16 01:14:26": 1,
    "16 01:13:07": 1,
    "16 00:18:02": 1,
    "15 22:11:02": 2,
    "15 16:49:05": 1,
    "15 16:47:38": 1,
    "16 19:19:41": 1,
    "16 19:18:37": 1,
    "16 17:03:49": 1,
    "16 14:54:24": 1,
    "16 02:27:09": 1,
    "16 02:23:09": 1,
    "16 18:22:01": 1,
    "16 18:22:00": 1,
    "16 17:03:16": 1,
    "15 16:13:21": 2,
    "15 16:13:20": 1,
    "15 14:51:44": 2,
    "15 13:18:04": 1,
    "15 13:18:03": 1,
    "15 06:07:46": 1,
    "15 06:07:45": 1,
    "14 16:41:14": 1,
    "14 14:59:23": 1,
    "14 05:20:51": 1,
    "16 22:55:53": 1,
    "16 19:01:57": 1,
    "16 19:01:30": 1,
    "16 18:59:55": 1,
    "16 23:15:39": 1,
    "16 23:10:07": 1,
    "16 11:55:30": 1,
    "15 21:33:57": 1,
    "15 16:43:20": 1,
    "15 11:14:55": 1,
    "14 23:53:16": 1,
    "14 21:16:26": 1,
    "14 17:05:13": 1,
    "14 15:54:25": 1,
    "13 14:09:45": 1,
    "13 14:08:10": 1,
    "13 09:49:27": 1,
    "12 23:16:59": 1,
    "12 22:40:00": 1,
    "12 00:25:00": 1,
    "12 00:24:18": 1,
    "15 23:25:23": 1,
    "15 13:48:08": 1,
    "16 14:50:43": 1,
    "15 05:31:36": 1,
    "14 15:14:24": 1,
    "14 06:15:06": 1,
    "14 05:52:20": 1,
    "14 05:30:02": 1,
    "13 15:43:29": 1,
    "13 14:56:47": 1,
    "13 13:39:49": 1,
    "13 13:38:57": 1,
    "13 13:36:43": 1,
    "13 13:30:24": 1,
    "13 13:22:40": 1,
    "13 13:16:15": 1,
    "13 12:52:17": 1,
    "17 04:49:46": 1,
    "17 03:58:31": 1,
    "17 03:57:22": 1,
    "17 02:11:36": 1,
    "16 22:30:53": 1,
    "16 21:28:16": 1,
    "16 21:24:15": 1,
    "17 08:50:04": 1,
    "17 08:10:03": 1,
    "17 08:00:06": 1,
    "17 07:10:03": 1,
    "17 06:50:04": 1,
    "17 03:00:06": 1,
    "17 02:30:05": 1,
    "17 02:00:06": 1,
    "16 22:45:05": 1,
    "16 11:25:03": 1,
    "16 09:15:05": 1,
    "16 08:55:03": 1,
    "16 07:50:03": 1,
    "16 07:45:06": 1,
    "16 06:50:04": 1,
    "16 19:09:53": 1,
    "16 18:02:27": 1,
    "16 18:01:40": 1,
    "15 20:50:01": 1,
    "15 18:23:17": 1,
    "15 17:49:34": 1,
    "15 17:40:31": 1,
    "15 17:22:51": 1,
    "13 21:20:12": 1,
    "13 21:14:38": 1,
    "13 04:00:54": 1,
    "13 03:40:29": 1,
    "11 03:07:19": 1,
    "16 17:36:05": 1,
    "16 17:36:02": 1,
    "16 17:36:00": 1,
    "16 17:35:57": 1,
    "16 17:35:54": 2,
    "16 17:35:51": 1,
    "16 17:35:47": 1,
    "16 17:35:43": 1,
    "16 17:35:39": 1,
    "16 17:35:36": 1,
    "15 17:03:10": 1,
    "15 17:01:37": 1,
    "15 17:01:34": 1,
    "15 17:01:31": 1,
    "15 17:01:27": 1,
    "14 22:04:33": 1,
    "16 12:57:11": 1,
    "16 12:51:25": 1,
    "16 12:20:17": 1,
    "16 04:26:04": 1,
    "16 04:08:17": 1,
    "16 01:50:44": 1,
    "16 01:14:22": 1,
    "16 01:09:42": 1,
    "16 00:51:13": 1,
    "16 00:36:11": 1,
    "15 13:33:29": 1,
    "15 12:23:04": 1,
    "14 18:44:26": 1,
    "14 18:44:25": 1,
    "17 11:34:34": 1,
    "17 03:17:59": 1,
    "17 01:36:41": 1,
    "17 01:33:39": 1,
    "17 01:10:16": 1,
    "17 00:48:31": 1,
    "17 00:48:08": 1,
    "17 00:33:34": 1,
    "17 00:13:22": 1,
    "16 23:05:15": 1,
    "16 23:05:14": 1,
    "16 22:40:24": 1,
    "16 22:18:06": 1,
    "17 00:44:42": 1,
    "17 00:33:17": 1,
    "16 20:26:57": 1,
    "16 20:26:27": 1,
    "16 18:53:45": 1,
    "16 15:51:13": 1,
    "17 04:21:53": 1,
    "17 02:25:14": 1,
    "16 20:40:30": 1,
    "16 15:41:57": 1,
    "16 03:16:56": 1,
    "15 23:25:08": 1,
    "16 23:46:53": 1,
    "16 23:45:23": 2,
    "16 23:45:22": 1,
    "16 23:45:20": 2,
    "16 23:45:18": 1,
    "16 23:45:17": 2,
    "16 23:45:16": 1,
    "17 10:16:30": 1,
    "17 00:00:00": 1,
    "16 20:00:00": 2,
    "16 16:30:00": 1,
    "15 21:35:38": 1,
    "15 16:05:56": 1,
    "14 22:00:01": 1,
    "14 19:00:00": 1,
    "13 19:00:06": 1,
    "13 19:00:05": 1,
    "13 19:00:04": 1,
    "13 19:00:02": 1,
    "13 19:00:01": 1,
    "13 19:00:00": 1,
    "11 18:38:10": 1,
    "15 23:39:47": 1,
    "15 13:20:49": 1,
    "14 21:57:00": 1,
    "14 19:17:18": 1,
    "14 19:15:08": 1,
    "14 14:40:22": 1,
    "14 13:20:30": 1,
    "12 20:04:37": 1,
    "10 23:07:50": 1,
    "11 14:26:00": 1,
    "17 10:49:26": 1,
    "17 10:22:45": 1,
    "17 09:22:42": 1,
    "17 07:49:45": 1,
    "17 06:59:33": 1,
    "17 06:56:33": 1,
    "17 06:24:08": 1,
    "17 05:57:42": 1,
    "17 05:47:45": 1,
    "17 04:52:04": 1,
    "17 04:29:14": 1,
    "17 04:26:00": 1,
    "17 09:54:58": 1,
    "17 09:20:11": 1,
    "16 20:40:22": 1,
    "16 17:24:06": 1,
    "16 17:15:56": 1,
    "16 16:34:35": 1,
    "16 16:25:27": 1,
    "16 10:29:01": 1,
    "16 08:03:06": 1,
    "15 19:43:19": 1,
    "13 21:47:23": 1,
    "12 01:24:49": 1,
    "12 00:15:36": 1,
    "10 20:48:21": 1,
    "10 20:00:27": 1,
    "10 19:59:31": 1,
    "10 19:58:27": 1,
    "16 12:42:17": 1,
    "16 12:38:46": 1,
    "15 16:41:08": 1,
    "15 16:38:57": 1,
    "15 16:33:19": 1,
    "15 14:29:53": 1,
    "15 03:34:13": 1,
    "15 01:30:31": 1,
    "14 15:18:36": 1,
    "13 16:19:12": 1,
    "13 14:03:12": 1,
    "17 08:36:53": 1,
    "17 08:35:32": 1,
    "17 08:34:38": 1,
    "17 08:33:22": 1,
    "17 08:31:49": 1,
    "17 08:30:08": 1,
    "17 08:28:30": 1,
    "17 08:27:22": 1,
    "17 08:26:01": 1,
    "16 09:05:40": 1,
    "16 09:00:57": 1,
    "16 08:34:51": 1,
    "16 08:23:18": 1,
    "16 08:16:35": 1,
    "16 08:13:07": 1,
    "16 08:11:47": 1,
    "16 07:37:19": 1,
    "16 05:09:51": 1,
    "17 11:30:00": 2,
    "16 10:49:55": 1,
    "13 10:13:54": 1,
    "12 18:46:30": 1,
    "11 07:19:53": 1,
    "16 17:31:49": 1,
    "16 17:31:18": 1,
    "16 17:27:02": 1,
    "16 14:13:26": 1,
    "16 14:12:49": 1,
    "16 14:12:48": 1,
    "16 13:59:26": 1,
    "16 13:46:51": 1,
    "16 13:44:38": 1,
    "16 13:42:30": 1,
    "16 13:42:29": 1,
    "16 12:21:02": 1,
    "17 10:03:28": 1,
    "17 08:41:48": 1,
    "17 08:21:10": 1,
    "17 07:19:54": 1,
    "17 02:07:07": 1,
    "17 00:19:28": 1,
    "17 00:13:46": 1,
    "16 22:08:44": 1,
    "16 04:27:13": 1,
    "15 22:28:59": 1,
    "15 22:24:58": 1,
    "15 06:02:11": 1,
    "15 03:29:56": 1,
    "16 16:26:01": 1,
    "14 15:03:03": 1,
    "16 16:31:56": 1,
    "16 01:03:56": 1,
    "15 23:40:55": 1,
    "15 17:28:22": 1,
    "14 22:42:30": 1,
    "13 20:17:38": 1,
    "13 19:53:47": 1,
    "13 18:51:29": 1,
    "17 08:03:04": 1,
    "17 04:01:37": 1,
    "17 00:01:29": 1,
    "16 20:02:35": 1,
    "16 16:08:13": 1,
    "16 12:04:21": 1,
    "16 08:01:50": 1,
    "16 04:01:03": 1,
    "16 00:01:05": 1,
    "15 20:02:11": 1,
    "15 16:07:23": 1,
    "15 12:03:50": 1,
    "15 08:02:10": 1,
    "15 04:01:03": 1,
    "15 00:01:24": 1,
    "14 20:02:49": 1,
    "14 16:07:15": 1,
    "14 14:01:18": 1,
    "14 12:03:35": 1,
    "14 08:01:53": 1,
    "17 08:00:54": 1,
    "17 05:22:41": 1,
    "17 04:43:37": 1,
    "17 04:14:07": 1,
    "16 15:22:18": 1,
    "17 01:09:06": 1,
    "16 23:25:01": 1,
    "16 03:21:07": 1,
    "16 00:22:50": 1,
    "16 00:09:53": 1,
    "16 00:09:52": 1,
    "16 00:09:51": 1,
    "15 18:05:21": 1,
    "15 17:59:01": 1,
    "15 17:47:09": 1,
    "15 17:42:15": 1,
    "15 17:14:11": 1,
    "15 07:01:15": 1,
    "15 06:55:02": 1,
    "15 01:12:51": 1,
    "15 01:12:50": 1,
    "17 10:23:12": 1,
    "17 06:26:42": 1,
    "17 04:58:01": 1,
    "17 03:31:38": 1,
    "17 00:29:58": 1,
    "16 23:49:12": 1,
    "16 22:03:26": 1,
    "16 08:21:06": 1,
    "16 20:40:05": 1,
    "16 19:27:35": 1,
    "16 19:24:46": 1,
    "15 22:18:35": 1,
    "15 19:37:27": 1,
    "16 19:51:56": 1,
    "16 16:19:24": 1,
    "16 16:03:44": 1,
    "16 16:03:28": 1,
    "16 10:41:58": 1,
    "16 18:13:34": 1,
    "16 17:20:42": 1,
    "16 17:20:39": 1,
    "16 17:20:33": 1,
    "16 17:20:30": 1,
    "16 17:20:28": 1,
    "16 17:20:25": 1,
    "16 17:20:19": 1,
    "16 17:20:16": 1,
    "16 17:20:13": 1,
    "16 17:20:11": 1,
    "16 17:20:08": 1,
    "16 17:20:05": 1,
    "16 17:20:02": 1,
    "16 17:19:59": 1,
    "16 20:02:32": 1,
    "16 19:19:50": 1,
    "15 17:57:49": 1,
    "12 20:13:39": 1,
    "17 08:29:05": 1,
    "17 07:39:04": 1,
    "17 07:21:10": 1,
    "17 07:03:07": 1,
    "17 06:56:10": 1,
    "17 06:24:06": 1,
    "17 06:07:06": 1,
    "17 05:32:05": 1,
    "17 04:05:07": 1,
    "17 02:35:05": 1,
    "17 01:40:05": 1,
    "17 01:10:06": 1,
    "17 01:01:08": 1,
    "17 00:50:06": 1,
    "16 23:38:06": 1,
    "16 22:30:06": 1,
    "16 21:45:05": 1,
    "17 10:05:55": 1,
    "17 09:03:53": 1,
    "17 06:07:46": 1,
    "17 01:33:55": 1,
    "17 00:51:58": 1,
    "16 22:42:30": 1,
    "16 21:33:53": 1,
    "16 19:33:48": 1,
    "16 19:11:47": 1,
    "16 18:23:46": 1,
    "16 18:23:45": 1,
    "16 17:53:44": 1,
    "16 16:06:40": 1,
    "16 15:34:39": 1,
    "16 15:13:38": 1,
    "16 14:53:37": 1,
    "16 14:34:36": 1,
    "16 14:23:36": 1,
    "16 14:06:35": 2,
    "17 10:21:07": 1,
    "16 13:07:47": 1,
    "17 09:46:53": 1,
    "17 09:41:49": 1,
    "17 09:38:28": 1,
    "17 09:36:17": 1,
    "17 08:25:18": 1,
    "17 07:52:52": 1,
    "17 07:51:17": 1,
    "16 15:16:51": 1,
    "16 12:13:36": 1,
    "16 12:10:57": 1,
    "16 12:09:24": 1,
    "16 11:17:08": 1,
    "17 08:02:14": 1,
    "17 08:02:12": 1,
    "16 21:22:08": 1,
    "16 17:34:45": 1,
    "16 17:34:43": 1,
    "16 17:34:41": 1,
    "16 17:34:38": 1,
    "13 12:32:37": 1,
    "16 11:51:19": 1,
    "16 11:49:22": 1,
    "16 11:49:20": 1,
    "16 11:41:06": 1,
    "16 11:40:20": 1,
    "16 11:37:24": 1,
    "17 11:00:02": 1,
    "17 10:30:00": 2,
    "17 09:30:00": 3,
    "17 09:00:03": 1,
    "17 05:27:26": 1,
    "17 08:30:46": 1,
    "17 08:30:45": 1,
    "17 08:30:44": 1,
    "17 08:30:42": 1,
    "17 08:30:30": 1,
    "17 08:30:19": 1,
    "17 08:29:58": 1,
    "17 08:29:35": 1,
    "17 08:29:26": 1,
    "17 08:29:14": 1,
    "17 08:29:01": 1,
    "16 04:39:36": 1,
    "16 04:39:35": 1,
    "16 04:39:25": 1,
    "16 04:39:15": 1,
    "16 04:39:05": 1,
    "15 18:05:38": 1,
    "17 11:15:52": 1,
    "17 08:39:57": 1,
    "17 08:20:43": 1,
    "17 08:19:36": 1,
    "17 07:56:04": 1,
    "17 11:00:01": 1,
    "17 10:00:03": 1,
    "17 09:00:04": 1,
    "17 08:42:48": 2,
    "17 08:30:00": 1,
    "17 08:03:35": 2,
    "17 06:51:57": 1,
    "17 06:00:01": 1,
    "17 04:46:00": 1,
    "16 20:30:00": 1,
    "16 18:00:01": 1,
    "16 17:30:00": 2,
    "16 15:02:35": 1,
    "16 14:51:38": 1,
    "16 14:30:00": 1,
    "17 11:26:26": 2,
    "17 10:28:10": 1,
    "17 08:26:57": 1,
    "17 08:23:25": 1,
    "17 08:15:18": 1,
    "17 08:07:52": 1,
    "17 05:22:39": 1,
    "17 05:07:13": 1,
    "17 04:26:32": 1,
    "17 04:22:45": 1,
    "17 04:17:05": 1,
    "17 03:02:58": 1,
    "17 03:01:09": 1,
    "17 02:58:39": 1,
    "17 02:54:16": 1,
    "17 02:23:49": 1,
    "17 02:17:18": 1,
    "16 23:28:26": 1,
    "16 23:28:25": 1,
    "15 19:12:15": 1,
    "15 19:12:14": 1,
    "15 18:10:25": 2,
    "14 20:29:09": 1,
    "14 20:29:08": 1,
    "14 18:33:16": 2,
    "14 17:22:23": 2,
    "13 20:39:05": 2,
    "13 20:39:04": 1,
    "13 20:08:44": 2,
    "17 10:44:22": 1,
    "17 07:58:06": 1,
    "17 06:54:57": 1,
    "17 04:46:22": 1,
    "17 02:31:34": 1,
    "16 05:06:51": 1,
    "15 16:09:00": 1,
    "15 13:22:00": 1,
    "15 12:50:39": 1,
    "15 11:27:00": 1,
    "15 06:22:00": 1,
    "15 04:12:00": 1,
    "15 02:08:14": 1,
    "17 10:34:05": 1,
    "17 11:21:00": 1,
    "17 08:51:00": 1,
    "17 08:36:15": 1,
    "17 06:20:00": 1,
    "17 05:16:00": 1,
    "17 04:34:00": 1,
    "17 03:26:07": 1,
    "17 03:12:02": 1,
    "17 02:52:00": 1,
    "16 15:57:11": 1,
    "16 03:30:31": 1,
    "15 16:00:35": 1,
    "15 16:00:32": 1,
    "15 16:00:29": 1,
    "15 16:00:26": 1,
    "15 16:00:24": 1,
    "15 16:00:21": 1,
    "15 01:39:06": 1,
    "14 20:56:23": 1,
    "14 20:55:38": 1,
    "14 20:51:48": 1,
    "14 15:41:07": 1,
    "17 06:55:28": 1,
    "16 19:04:06": 1,
    "16 18:05:09": 1,
    "16 17:01:46": 1,
    "15 22:22:22": 1,
    "15 22:16:02": 1,
    "15 03:16:42": 1,
    "14 17:20:03": 1,
    "17 03:40:18": 1,
    "17 02:19:03": 1,
    "16 13:51:02": 1,
    "16 13:13:18": 1,
    "16 13:08:40": 1,
    "16 12:31:21": 1,
    "16 11:00:13": 1,
    "16 06:58:47": 1,
    "16 00:46:35": 1,
    "16 00:18:39": 1,
    "15 10:55:46": 1,
    "15 07:57:06": 1,
    "15 07:45:46": 1,
    "15 04:06:36": 1,
    "17 04:27:05": 1,
    "17 00:56:19": 1,
    "16 22:12:17": 1,
    "16 21:21:50": 1,
    "16 20:49:08": 1,
    "16 20:34:40": 1,
    "16 20:16:46": 2,
    "17 02:55:20": 1,
    "16 23:25:21": 1,
    "16 17:12:59": 1,
    "16 07:18:20": 1,
    "16 06:33:58": 1,
    "16 06:29:25": 1,
    "16 03:32:42": 1,
    "16 01:16:33": 1,
    "16 01:00:29": 1,
    "15 23:35:55": 1,
    "15 21:35:33": 1,
    "15 19:32:37": 1,
    "16 22:41:57": 1,
    "16 22:36:19": 1,
    "17 07:11:04": 1,
    "17 01:40:18": 1,
    "16 23:14:37": 1,
    "16 23:11:41": 1,
    "16 21:17:13": 1,
    "16 21:13:12": 1,
    "16 21:11:34": 1,
    "16 18:46:43": 1,
    "16 17:20:34": 1,
    "16 16:28:26": 1,
    "17 03:33:49": 1,
    "16 16:05:40": 1,
    "16 15:50:58": 1,
    "16 15:45:31": 1,
    "16 14:06:40": 1,
    "16 13:54:41": 1,
    "16 05:26:17": 1,
    "16 02:32:04": 1,
    "15 23:11:28": 1,
    "17 11:28:54": 1,
    "17 11:28:35": 1,
    "17 11:28:14": 1,
    "17 11:27:57": 1,
    "17 11:27:37": 1,
    "17 11:27:19": 1,
    "17 11:27:02": 1,
    "17 11:26:44": 1,
    "17 11:26:07": 1,
    "17 08:47:03": 1,
    "17 08:47:00": 1,
    "17 08:46:44": 1,
    "17 08:46:27": 1,
    "17 08:46:11": 1,
    "17 08:45:54": 1,
    "17 08:45:38": 1,
    "16 18:47:02": 1,
    "16 18:36:01": 1,
    "17 11:50:00": 1,
    "17 11:40:00": 1,
    "17 11:20:00": 1,
    "17 11:10:00": 1,
    "17 11:00:00": 1,
    "17 10:50:00": 1,
    "17 10:40:00": 1,
    "17 10:20:00": 1,
    "17 10:10:00": 1,
    "17 10:00:01": 2,
    "17 09:52:06": 1,
    "17 09:40:00": 1,
    "17 09:20:00": 1,
    "17 09:10:00": 1,
    "17 09:00:02": 1,
    "17 08:50:00": 1,
    "17 00:14:39": 1,
    "17 00:13:51": 1,
    "16 22:06:57": 1,
    "16 21:25:20": 1,
    "16 21:17:03": 1,
    "16 15:31:02": 1,
    "17 06:26:38": 1,
    "17 02:27:25": 1,
    "17 02:27:23": 1,
    "17 02:27:20": 1,
    "17 02:27:17": 1,
    "16 17:11:00": 1,
    "17 04:30:41": 1,
    "17 03:56:30": 1,
    "17 03:03:23": 1,
    "17 02:03:22": 1,
    "17 01:42:01": 1,
    "16 23:43:28": 1,
    "16 19:57:18": 1,
    "16 18:15:19": 1,
    "16 17:53:01": 1,
    "16 17:44:35": 1,
    "16 17:37:31": 1,
    "16 17:09:52": 1,
    "16 16:56:59": 1,
    "16 15:32:27": 1,
    "17 02:53:18": 1,
    "17 02:53:15": 1,
    "16 15:45:50": 1,
    "15 19:55:46": 1,
    "15 16:29:10": 1,
    "14 15:42:24": 1,
    "14 15:42:22": 1,
    "13 15:50:29": 1,
    "13 00:22:39": 1,
    "12 17:03:24": 1,
    "11 22:52:34": 1,
    "11 21:24:51": 1,
    "11 17:41:42": 1,
    "11 16:59:02": 1,
    "17 10:32:42": 1,
    "17 08:31:08": 1,
    "17 08:41:23": 1,
    "17 07:10:30": 1,
    "17 06:34:15": 1,
    "17 06:26:09": 1,
    "17 05:21:02": 1,
    "17 04:45:18": 1,
    "15 23:33:09": 1,
    "15 21:23:38": 1,
    "15 04:34:14": 1,
    "14 20:18:07": 1,
    "17 00:32:05": 1,
    "16 03:49:21": 1,
    "16 02:12:59": 1,
    "16 00:16:49": 1,
    "14 16:59:02": 1,
    "13 23:15:59": 1,
    "13 05:22:00": 1,
    "12 21:33:09": 1,
    "12 01:54:53": 1,
    "12 01:11:38": 1,
    "11 18:31:41": 1,
    "11 02:38:17": 1,
    "17 09:44:21": 1,
    "17 08:51:23": 1,
    "17 02:30:29": 1,
    "17 00:04:31": 1,
    "16 23:44:57": 1,
    "16 19:46:34": 1,
    "16 17:39:53": 1,
    "16 17:37:02": 1,
    "16 01:45:54": 1,
    "15 19:30:24": 1,
    "15 19:10:22": 1,
    "15 18:04:25": 1,
    "15 17:27:15": 1,
    "15 17:09:34": 1,
    "15 02:37:04": 1,
    "14 23:28:51": 1,
    "17 09:30:26": 1,
    "17 09:29:08": 1,
    "17 08:19:09": 1,
    "17 08:14:05": 1,
    "17 08:13:13": 1,
    "17 08:08:33": 1,
    "16 08:00:11": 1,
    "16 07:59:10": 1,
    "16 07:58:18": 1,
    "14 15:00:25": 1,
    "14 15:00:24": 1,
    "14 15:00:23": 1,
    "14 15:00:21": 1,
    "13 01:46:13": 1,
    "13 01:45:36": 1,
    "13 01:45:10": 1,
    "12 11:10:39": 1,
    "17 11:21:38": 1,
    "17 10:07:13": 1,
    "17 10:07:11": 1,
    "17 09:00:30": 1,
    "17 08:00:00": 1,
    "17 07:03:58": 1,
    "17 07:02:50": 1,
    "16 17:38:29": 1,
    "16 16:30:01": 1,
    "16 15:30:30": 1,
    "16 20:08:20": 1,
    "16 15:09:41": 1,
    "16 14:57:00": 1,
    "16 03:26:22": 1,
    "16 03:25:33": 1,
    "17 09:04:22": 1,
    "16 14:52:13": 1,
    "16 14:33:24": 1,
    "16 07:11:38": 1,
    "16 04:22:00": 1,
    "15 23:01:45": 1,
    "15 22:12:59": 1,
    "15 22:12:58": 1,
    "15 19:04:50": 1,
    "15 18:06:27": 1,
    "15 15:58:18": 1,
    "17 08:06:38": 1,
    "17 03:48:16": 1,
    "17 00:53:52": 1,
    "17 00:27:49": 1,
    "17 00:00:05": 1,
    "16 16:58:56": 1,
    "16 20:09:29": 1,
    "16 16:03:13": 1,
    "16 15:47:21": 1,
    "16 02:57:22": 1,
    "16 01:52:38": 1,
    "17 10:30:19": 1,
    "17 06:30:01": 1,
    "16 17:03:27": 1,
    "17 02:38:22": 1,
    "17 02:22:56": 1,
    "17 02:22:55": 1,
    "17 02:22:54": 1,
    "17 02:22:53": 1,
    "17 02:22:51": 1,
    "17 02:22:49": 1,
    "16 14:56:17": 1,
    "16 14:47:50": 1,
    "16 14:47:35": 1,
    "17 09:47:45": 1,
    "17 09:38:51": 1,
    "16 16:15:23": 1,
    "16 16:14:54": 1,
    "16 16:12:23": 1,
    "16 16:09:31": 1,
    "17 03:41:38": 1,
    "17 03:41:35": 1,
    "17 03:41:29": 1,
    "16 03:27:34": 1,
    "16 03:27:32": 1,
    "16 03:27:28": 1,
    "15 18:31:23": 1,
    "15 17:35:08": 2,
    "15 17:35:07": 1,
    "14 22:23:04": 1,
    "14 22:00:11": 1,
    "17 02:24:22": 1,
    "17 00:49:50": 1,
    "16 21:47:30": 1,
    "16 21:10:53": 1,
    "16 20:29:02": 1,
    "16 18:28:17": 1,
    "16 16:33:38": 1,
    "16 02:37:34": 1,
    "16 02:29:47": 1,
    "16 01:25:45": 1,
    "16 01:01:30": 1,
    "16 15:38:53": 1,
    "16 14:49:21": 1,
    "16 14:45:01": 1,
    "16 14:42:52": 1,
    "16 14:35:24": 1,
    "16 14:27:06": 1,
    "16 14:14:27": 1,
    "16 11:09:58": 1,
    "16 10:34:02": 1,
    "16 08:25:19": 1,
    "17 07:56:09": 1,
    "17 10:35:46": 1,
    "17 10:14:48": 1,
    "17 09:36:50": 1,
    "17 04:19:37": 1,
    "17 00:01:58": 1,
    "16 23:16:44": 1,
    "16 05:49:59": 1,
    "15 22:37:11": 1,
    "15 22:14:19": 1,
    "17 03:40:00": 1,
    "16 22:20:29": 1,
    "16 18:42:16": 1,
    "16 18:42:15": 1,
    "16 18:42:11": 1,
    "16 10:15:01": 1,
    "16 04:48:16": 1,
    "15 21:23:20": 1,
    "15 18:51:11": 1,
    "15 18:51:10": 3,
    "17 01:43:38": 1,
    "17 01:43:37": 1,
    "16 17:13:19": 1,
    "16 14:00:45": 2,
    "16 04:57:23": 1,
    "16 02:03:51": 1,
    "15 04:22:24": 1,
    "14 14:02:46": 1,
    "14 06:02:48": 1,
    "13 02:44:44": 1,
    "13 00:31:05": 1,
    "13 00:07:47": 1,
    "16 10:05:10": 1,
    "16 09:27:36": 1,
    "16 06:45:51": 1,
    "15 06:50:42": 1,
    "14 13:14:13": 1,
    "14 07:54:01": 1,
    "16 18:38:25": 1,
    "16 18:35:34": 1,
    "15 21:58:48": 2,
    "15 18:14:39": 1,
    "13 18:15:47": 1,
    "17 10:01:15": 1,
    "16 11:09:41": 1,
    "16 10:56:39": 1,
    "16 07:26:23": 1,
    "14 13:46:33": 1,
    "14 10:42:58": 1,
    "14 07:29:00": 1,
    "14 06:38:20": 1,
    "13 08:59:21": 1,
    "13 08:48:49": 1,
    "13 08:17:34": 1,
    "12 14:16:04": 1,
    "12 13:53:06": 1,
    "12 08:54:01": 1,
    "17 07:10:25": 1,
    "16 17:22:53": 1,
    "16 12:49:31": 1,
    "15 18:10:50": 1,
    "15 13:57:25": 1,
    "15 13:52:34": 1,
    "14 20:41:11": 1,
    "14 19:45:39": 1,
    "14 16:17:40": 1,
    "14 10:24:46": 1,
    "16 23:30:27": 1,
    "16 20:01:32": 1,
    "16 16:02:09": 1,
    "16 12:01:37": 1,
    "15 23:30:29": 1,
    "15 20:01:32": 1,
    "15 16:02:10": 1,
    "15 12:01:43": 1,
    "14 23:30:29": 1,
    "14 22:42:32": 1,
    "14 21:18:54": 1,
    "14 21:18:53": 1,
    "14 19:34:03": 1,
    "14 18:01:54": 1,
    "14 16:02:09": 1,
    "14 14:02:01": 1,
    "14 12:01:45": 2,
    "14 00:01:30": 1,
    "16 20:13:59": 1,
    "16 19:29:47": 1,
    "15 14:44:14": 1,
    "14 22:08:38": 1,
    "14 21:11:56": 2,
    "13 15:35:00": 1,
    "13 15:34:59": 1,
    "16 23:57:48": 1,
    "16 23:57:09": 1,
    "16 23:39:45": 1,
    "17 07:55:06": 1,
    "17 01:41:56": 1,
    "16 23:38:56": 1,
    "16 23:23:15": 1,
    "16 23:16:53": 1,
    "16 23:13:58": 1,
    "16 23:10:29": 1,
    "16 23:06:08": 1,
    "16 22:52:25": 1,
    "16 22:51:16": 1,
    "16 22:49:43": 1,
    "16 22:45:29": 1,
    "16 22:39:44": 1,
    "16 06:41:22": 1,
    "17 08:44:12": 1,
    "17 03:11:06": 1,
    "17 01:18:19": 1,
    "16 23:41:04": 1,
    "16 23:32:10": 1,
    "16 15:43:34": 1,
    "16 14:58:31": 1,
    "16 05:31:03": 1,
    "16 01:33:05": 1,
    "15 18:10:00": 1,
    "16 17:34:59": 1,
    "16 17:34:56": 1,
    "16 17:34:53": 1,
    "15 16:23:29": 1,
    "15 16:23:26": 1,
    "15 16:23:23": 1,
    "15 16:23:20": 1,
    "15 16:23:16": 1,
    "15 16:23:13": 1,
    "15 16:23:10": 1,
    "15 16:23:06": 1,
    "13 20:48:46": 1,
    "17 10:36:17": 1,
    "16 11:12:00": 1,
    "15 11:47:00": 1,
    "15 06:20:17": 1,
    "14 14:12:42": 1,
    "14 14:12:08": 1,
    "13 17:52:25": 1,
    "17 06:51:24": 1,
    "17 04:33:39": 1,
    "17 02:37:43": 1,
    "16 23:44:23": 1,
    "16 06:45:31": 1,
    "16 08:25:48": 1,
    "16 04:55:59": 1,
    "14 14:01:55": 1,
    "14 12:59:34": 1,
    "14 12:48:38": 1,
    "14 12:46:00": 1,
    "14 12:12:46": 1,
    "13 02:48:19": 1,
    "13 01:07:03": 1,
    "13 01:05:31": 1,
    "13 00:58:19": 1,
    "17 06:13:13": 1,
    "17 06:11:38": 1,
    "17 06:11:22": 1,
    "16 20:45:38": 1,
    "16 20:45:36": 1,
    "16 20:45:20": 1,
    "16 20:45:04": 1,
    "16 20:44:49": 1,
    "16 20:44:32": 1,
    "16 20:44:16": 1,
    "16 20:44:01": 1,
    "16 20:43:46": 1,
    "16 20:43:30": 1,
    "17 11:00:04": 1,
    "17 04:39:52": 1,
    "17 03:00:08": 1,
    "16 22:00:04": 1,
    "17 11:08:48": 1,
    "17 11:06:47": 1,
    "17 11:05:57": 1,
    "17 10:59:12": 1,
    "17 10:53:59": 1,
    "17 10:52:45": 1,
    "17 10:39:29": 1,
    "17 10:00:00": 1,
    "17 09:00:01": 1,
    "16 11:00:01": 1,
    "16 11:00:00": 1,
    "16 10:00:00": 1,
    "16 05:01:16": 1,
    "15 11:00:00": 1,
    "15 10:00:00": 1,
    "15 09:00:00": 1,
    "15 08:00:01": 1,
    "14 12:15:07": 1,
    "14 11:48:42": 1,
    "14 10:00:00": 1,
    "14 09:00:01": 1,
    "14 09:00:00": 1,
    "13 09:00:00": 1,
    "12 10:00:52": 1,
    "11 12:30:00": 1,
    "11 11:44:44": 1,
    "16 09:31:50": 1,
    "16 03:19:22": 1,
    "16 20:31:15": 1,
    "16 20:26:47": 1,
    "16 20:15:49": 1,
    "17 08:52:27": 1,
    "16 17:03:35": 1,
    "16 15:58:44": 1,
    "16 10:13:24": 1,
    "16 10:10:46": 1,
    "15 18:12:28": 1,
    "15 16:43:23": 1,
    "15 13:57:28": 1,
    "15 11:57:02": 1,
    "15 20:04:51": 1,
    "15 20:04:42": 1,
    "15 15:30:19": 1,
    "15 02:00:00": 1,
    "14 02:59:59": 1,
    "13 22:15:54": 1,
    "17 10:07:52": 1,
    "16 13:35:15": 1,
    "13 23:44:07": 1,
    "13 02:31:52": 1,
    "13 02:30:27": 1,
    "13 02:20:34": 1,
    "13 02:09:00": 1,
    "15 14:19:38": 1,
    "14 07:22:05": 1,
    "13 19:12:51": 1,
    "13 16:18:07": 1,
    "13 16:14:35": 1,
    "16 18:50:41": 1,
    "16 18:36:39": 1,
    "15 22:28:40": 1,
    "15 17:59:21": 1,
    "14 19:57:09": 1,
    "16 21:09:57": 1,
    "16 09:31:34": 1,
    "16 05:16:44": 1,
    "17 10:04:33": 1,
    "17 10:03:29": 1,
    "16 11:10:01": 1,
    "16 09:22:01": 1,
    "16 08:58:19": 1,
    "15 12:08:52": 1,
    "15 12:03:37": 1,
    "15 11:43:18": 1,
    "15 08:34:17": 1,
    "15 08:19:16": 1,
    "16 15:52:00": 1,
    "15 05:53:18": 1,
    "14 19:06:44": 1,
    "14 18:54:48": 1,
    "14 18:45:02": 1,
    "14 18:42:21": 1,
    "16 19:06:58": 1,
    "16 17:43:04": 1,
    "16 00:15:09": 1,
    "15 19:03:52": 1,
    "15 18:42:53": 1,
    "15 15:44:53": 1,
    "14 12:30:00": 1,
    "17 10:30:25": 1,
    "17 10:24:54": 1,
    "17 10:09:38": 1,
    "17 10:03:15": 1,
    "17 08:53:51": 1,
    "17 05:01:24": 1,
    "17 00:30:08": 1,
    "16 23:59:09": 1,
    "16 23:55:29": 1,
    "16 23:52:15": 1,
    "16 23:41:43": 1,
    "16 21:26:53": 1,
    "16 21:12:25": 1,
    "16 20:46:02": 1,
    "16 20:44:36": 1,
    "16 20:42:00": 1,
    "16 20:40:48": 1,
    "17 09:09:20": 1,
    "17 06:12:06": 1,
    "16 17:51:19": 1,
    "16 17:12:24": 1,
    "16 16:05:32": 1,
    "16 11:32:22": 1,
    "16 11:29:38": 1,
    "16 09:44:09": 1,
    "16 07:51:14": 1,
    "17 11:57:59": 1,
    "17 08:53:08": 1,
    "17 08:53:07": 1,
    "17 08:53:03": 1,
    "17 08:53:00": 1,
    "17 08:52:56": 1,
    "17 08:52:55": 1,
    "17 08:47:49": 1,
    "17 08:44:19": 1,
    "17 08:43:36": 1,
    "17 08:11:28": 1,
    "17 08:03:46": 1,
    "17 06:07:52": 1,
    "17 05:40:46": 1,
    "15 17:03:55": 1,
    "14 15:52:43": 1,
    "17 06:05:00": 1,
    "17 02:58:13": 1,
    "17 02:30:04": 1,
    "17 01:14:32": 1,
    "17 00:05:50": 1,
    "16 22:35:33": 1,
    "16 05:30:03": 1,
    "16 04:18:21": 1,
    "16 01:56:47": 1,
    "16 00:00:16": 1,
    "15 22:52:38": 1,
    "15 05:28:58": 1,
    "15 03:30:04": 1,
    "14 22:15:56": 1,
    "14 06:12:29": 1,
    "14 04:30:29": 1,
    "14 02:15:07": 1,
    "13 22:39:51": 1,
    "13 09:56:17": 1,
    "13 04:47:54": 1,
    "17 10:28:20": 1,
    "16 17:08:41": 1,
    "16 20:37:07": 1,
    "15 19:35:18": 1,
    "15 14:48:27": 1,
    "15 13:35:52": 1,
    "15 01:20:36": 1,
    "16 19:23:55": 1,
    "16 18:41:08": 1,
    "16 18:02:37": 1,
    "15 16:07:22": 2,
    "15 06:12:30": 1,
    "16 20:59:03": 1,
    "16 19:32:03": 1,
    "16 18:14:01": 2,
    "16 17:05:09": 1,
    "16 16:59:33": 1,
    "16 16:05:03": 1,
    "16 16:01:30": 1,
    "16 14:37:42": 1,
    "16 11:10:53": 1,
    "17 02:16:36": 1,
    "16 21:00:33": 1,
    "16 16:56:44": 1,
    "16 07:00:58": 1,
    "15 02:28:44": 1,
    "15 02:06:20": 1,
    "14 15:03:04": 1,
    "14 03:04:12": 1,
    "16 21:34:46": 1,
    "16 10:28:29": 1,
    "15 22:57:29": 1,
    "11 00:12:21": 1,
    "16 19:35:32": 1,
    "16 10:40:11": 1,
    "15 17:08:24": 2,
    "15 16:36:52": 1,
    "15 16:25:39": 1,
    "14 16:56:46": 1,
    "13 20:40:44": 1,
    "17 10:10:14": 1,
    "17 09:24:46": 1,
    "17 09:11:29": 1,
    "17 03:25:26": 1,
    "17 03:17:14": 1,
    "16 12:57:31": 1,
    "16 12:38:51": 1,
    "16 11:06:27": 1,
    "16 09:13:54": 1,
    "16 02:00:42": 1,
    "16 13:19:12": 1,
    "16 13:18:56": 1,
    "16 13:18:40": 1,
    "16 13:18:23": 1,
    "16 13:18:07": 1,
    "16 13:17:51": 1,
    "17 10:38:39": 1,
    "16 11:10:25": 1,
    "16 11:09:57": 1,
    "16 11:09:34": 1,
    "16 11:09:10": 1,
    "16 11:00:36": 1,
    "16 11:00:18": 1,
    "16 10:59:30": 1,
    "17 03:17:35": 1,
    "17 00:07:34": 1,
    "16 22:28:54": 1,
    "16 21:57:52": 1,
    "16 21:41:47": 1,
    "16 21:32:05": 1,
    "16 21:31:11": 1,
    "16 22:11:44": 1,
    "15 23:44:03": 1,
    "15 21:15:36": 1,
    "15 18:37:03": 1,
    "15 09:35:12": 1,
    "14 19:27:22": 1,
    "14 18:21:48": 1,
    "17 03:23:06": 1,
    "16 13:57:42": 1,
    "16 12:52:59": 1,
    "16 11:24:23": 1,
    "16 11:05:51": 1,
    "16 10:38:36": 1,
    "16 02:01:03": 1,
    "16 00:50:01": 1,
    "16 00:44:55": 1,
    "16 00:29:40": 1,
    "16 08:53:30": 1,
    "14 01:21:47": 1,
    "11 23:33:54": 1,
    "11 23:32:46": 1,
    "17 04:06:40": 1,
    "16 22:05:14": 1,
    "16 17:38:32": 1,
    "16 17:26:50": 1,
    "16 16:26:14": 1,
    "16 16:22:20": 2,
    "16 14:21:54": 1,
    "16 16:30:02": 1,
    "15 17:30:19": 1,
    "14 20:45:00": 1,
    "14 16:00:01": 1,
    "13 16:00:00": 1,
    "16 19:35:40": 1,
    "14 22:54:11": 1,
    "14 17:47:43": 1,
    "14 16:30:52": 1,
    "13 18:12:48": 1,
    "10 20:41:12": 1,
    "16 17:56:48": 1,
    "15 23:47:39": 1,
    "15 18:02:54": 2,
    "15 17:51:56": 1,
    "15 17:13:00": 1,
    "17 09:49:28": 1,
    "17 06:03:10": 1,
    "17 04:49:42": 1,
    "17 02:09:51": 1,
    "16 04:56:13": 1,
    "15 20:41:58": 1,
    "15 20:20:18": 1,
    "15 14:30:14": 1,
    "14 15:50:28": 1,
    "14 20:00:09": 1,
    "13 19:30:06": 1,
    "13 14:30:13": 1,
    "12 12:38:05": 1,
    "17 01:58:08": 1,
    "16 23:29:54": 1,
    "16 20:58:14": 1,
    "17 04:30:02": 1,
    "17 04:29:11": 1,
    "15 19:18:34": 1,
    "15 17:49:06": 1,
    "15 17:48:31": 1,
    "15 17:44:59": 1,
    "15 17:43:11": 1,
    "15 17:39:41": 1,
    "15 13:50:23": 1,
    "14 18:09:57": 1,
    "14 16:08:11": 1,
    "13 18:51:18": 1,
    "13 17:57:33": 1,
    "12 16:16:04": 1,
    "12 04:30:45": 1,
    "12 04:25:10": 1,
    "12 01:01:06": 1,
    "11 21:04:45": 1,
    "16 15:13:39": 1,
    "16 07:58:01": 1,
    "15 14:22:51": 1,
    "15 02:44:04": 1,
    "15 02:41:22": 1,
    "15 02:36:25": 1,
    "15 02:35:21": 1,
    "15 02:32:33": 1,
    "14 17:42:12": 1,
    "14 17:30:01": 1,
    "14 17:29:43": 1,
    "14 17:29:26": 1,
    "14 17:28:35": 1,
    "14 09:24:26": 1,
    "14 02:21:30": 1,
    "13 04:18:12": 1,
    "13 02:44:36": 1,
    "11 08:53:17": 1,
    "11 08:52:36": 1,
    "16 11:06:53": 1,
    "16 04:17:34": 1,
    "16 04:15:54": 1,
    "15 07:57:24": 1,
    "15 07:57:18": 1,
    "14 14:40:14": 1,
    "14 12:31:34": 1,
    "13 17:21:45": 1,
    "11 05:36:50": 1,
    "11 04:57:42": 2,
    "11 04:57:40": 1,
    "17 11:56:25": 1,
    "17 11:56:24": 1,
    "16 21:42:32": 1,
    "15 19:46:07": 1,
    "15 10:51:06": 1,
    "15 09:52:07": 1,
    "14 21:23:54": 1,
    "14 20:50:42": 1,
    "14 19:28:39": 1,
    "16 16:22:12": 1,
    "16 00:57:36": 1,
    "15 17:07:20": 1,
    "14 12:20:08": 1,
    "14 12:18:11": 1,
    "13 12:09:12": 1,
    "11 13:44:04": 1,
    "17 05:06:08": 1,
    "17 04:34:39": 1,
    "16 06:12:36": 1,
    "15 20:39:19": 1,
    "15 05:36:58": 1,
    "14 08:54:45": 1,
    "14 08:52:02": 1,
    "14 06:38:55": 1,
    "14 00:05:52": 1,
    "12 06:20:43": 1,
    "11 20:19:56": 1,
    "11 09:57:40": 1,
    "17 08:22:57": 1,
    "17 08:17:32": 1,
    "17 08:17:30": 1,
    "17 07:55:45": 1,
    "17 07:29:32": 1,
    "16 22:27:13": 1,
    "17 11:32:44": 1,
    "17 07:35:50": 1,
    "17 05:39:26": 1,
    "17 03:43:13": 1,
    "17 02:28:41": 1,
    "16 14:30:51": 1,
    "16 13:09:03": 1,
    "16 11:08:39": 1,
    "16 10:52:04": 1,
    "16 09:20:00": 1,
    "16 03:41:17": 1,
    "17 11:17:20": 1,
    "16 22:08:30": 1,
    "16 08:31:37": 1,
    "16 00:03:10": 1,
    "15 23:49:18": 1,
    "15 23:46:41": 1,
    "15 21:16:50": 1,
    "15 21:08:59": 1,
    "15 21:04:31": 1,
    "15 20:24:20": 1,
    "15 20:06:25": 1,
    "15 18:53:35": 1,
    "17 01:13:02": 1,
    "17 01:07:34": 1,
    "17 00:47:18": 1,
    "16 22:11:16": 1,
    "16 14:40:43": 1,
    "17 03:36:14": 1,
    "16 23:23:06": 1,
    "16 22:24:53": 1,
    "16 21:14:40": 1,
    "16 20:51:27": 1,
    "16 21:57:48": 1,
    "16 21:42:27": 1,
    "17 04:12:06": 1,
    "17 03:49:57": 1,
    "17 03:33:41": 1,
    "17 03:30:44": 1,
    "17 03:28:53": 1,
    "15 09:55:38": 1,
    "16 21:00:34": 1,
    "16 13:35:04": 1,
    "16 03:46:11": 1,
    "16 00:07:50": 1,
    "16 16:59:55": 1,
    "16 06:02:45": 1,
    "16 05:11:34": 1,
    "16 00:20:42": 1,
    "15 23:58:58": 1,
    "15 15:01:05": 1,
    "15 11:57:12": 1,
    "15 10:49:33": 1,
    "14 23:44:38": 1,
    "17 06:36:06": 1,
    "16 23:25:35": 1,
    "16 22:04:22": 1,
    "16 19:17:56": 1,
    "17 04:51:43": 1,
    "17 04:45:30": 1,
    "17 04:35:52": 1,
    "16 21:22:49": 1,
    "16 21:03:34": 1,
    "16 20:14:44": 1,
    "16 19:45:33": 1,
    "16 18:19:43": 1,
    "16 17:53:59": 1,
    "16 17:27:14": 1,
    "16 17:22:07": 1,
    "17 06:00:39": 1,
    "16 14:30:56": 1,
    "16 06:00:15": 1,
    "16 03:00:27": 1,
    "15 23:30:21": 1,
    "17 04:35:48": 1,
    "16 20:56:32": 1,
    "15 02:29:51": 2,
    "16 15:41:33": 1,
    "15 18:34:10": 1,
    "15 14:47:13": 1,
    "11 22:43:28": 1,
    "10 23:23:12": 1,
    "15 12:54:30": 1,
    "14 10:52:18": 1,
    "12 15:19:15": 1,
    "12 14:56:26": 1,
    "12 14:14:46": 1,
    "11 17:03:46": 1,
    "11 15:29:04": 1,
    "16 12:45:13": 1,
    "16 11:23:27": 1,
    "15 18:11:11": 1,
    "17 08:38:37": 1,
    "16 16:56:36": 1,
    "15 16:55:42": 1,
    "16 20:00:18": 1,
    "17 02:48:03": 1,
    "17 02:21:25": 1,
    "17 01:57:57": 1,
    "17 01:46:25": 1,
    "17 01:41:07": 1,
    "17 03:22:45": 1,
    "17 04:44:53": 2,
    "17 04:44:51": 1,
    "17 04:44:50": 1,
    "17 04:44:49": 1,
    "17 04:44:48": 1,
    "17 04:44:47": 1,
    "17 04:44:46": 1,
    "17 04:44:44": 1,
    "17 04:44:43": 1,
    "17 05:02:34": 1,
    "17 01:54:26": 1,
    "17 00:35:50": 1,
    "16 19:45:45": 1,
    "16 19:37:53": 1,
    "16 00:24:39": 1,
    "15 17:11:01": 1,
    "15 15:02:34": 1,
    "15 04:32:26": 1,
    "14 23:43:05": 1,
    "14 20:48:24": 1,
    "17 10:34:06": 1,
    "17 10:11:49": 1,
    "17 06:54:58": 1,
    "16 18:34:46": 1,
    "16 16:14:17": 1,
    "16 13:37:25": 1,
    "16 08:45:48": 1,
    "15 17:05:31": 1,
    "15 16:24:40": 1,
    "17 12:01:01": 1,
    "17 11:55:19": 1,
    "17 11:46:59": 1,
    "17 11:46:18": 1,
    "17 11:37:17": 1,
    "17 11:31:17": 1,
    "17 11:30:59": 1,
    "17 11:27:18": 1,
    "17 11:02:29": 1,
    "17 11:01:01": 1,
    "17 10:59:18": 1,
    "17 10:57:19": 1,
    "17 10:37:29": 1,
    "17 10:34:19": 1,
    "17 10:30:59": 1,
    "17 10:30:18": 1,
    "17 10:21:18": 1,
    "17 07:12:01": 1,
    "17 06:41:16": 1,
    "17 05:51:57": 1,
    "17 05:21:43": 1,
    "17 03:55:01": 1,
    "17 03:30:23": 1,
    "17 03:21:59": 1,
    "17 01:57:27": 1,
    "17 01:50:08": 1,
    "17 00:39:47": 1,
    "16 23:41:28": 1,
    "16 23:17:37": 1,
    "16 21:06:41": 1,
    "16 21:02:34": 1,
    "16 19:38:35": 1,
    "16 19:05:00": 1,
    "17 06:44:54": 1,
    "17 05:39:49": 1,
    "17 01:51:23": 1,
    "17 00:48:36": 1,
    "16 22:36:00": 1,
    "16 20:19:29": 1,
    "16 17:59:43": 1,
    "16 17:58:11": 1,
    "16 17:57:39": 1,
    "16 17:56:30": 1,
    "16 16:17:28": 1,
    "14 05:21:08": 1,
    "15 00:18:33": 1,
    "10 22:34:24": 1,
    "12 18:06:37": 1,
    "11 18:48:43": 1,
    "16 19:19:32": 1,
    "16 15:10:46": 1,
    "16 11:26:20": 1,
    "17 07:47:57": 1,
    "17 07:47:54": 1,
    "17 07:47:33": 1,
    "17 07:47:07": 1,
    "17 07:46:33": 1,
    "17 07:45:27": 1,
    "16 21:20:57": 1,
    "16 17:04:23": 1,
    "16 17:04:22": 1,
    "16 17:04:21": 1,
    "16 17:04:18": 1,
    "16 17:04:16": 1,
    "16 17:04:13": 1,
    "16 13:25:11": 1,
    "16 12:01:42": 1,
    "16 12:01:41": 1,
    "16 12:00:42": 1,
    "16 11:59:32": 1,
    "17 03:30:16": 1,
    "16 22:32:15": 1,
    "16 19:30:00": 1,
    "16 18:32:42": 1,
    "16 18:15:34": 1,
    "16 16:00:00": 1,
    "16 05:27:18": 1,
    "16 04:44:22": 1,
    "16 01:43:25": 1,
    "16 16:51:32": 1,
    "15 19:10:00": 1,
    "15 18:03:57": 2,
    "15 16:29:14": 1,
    "15 16:22:48": 1,
    "15 12:08:05": 1,
    "14 16:47:49": 1,
    "14 12:44:24": 1,
    "14 12:44:23": 1,
    "13 17:54:01": 1,
    "17 07:49:27": 1,
    "16 17:22:15": 1,
    "16 12:44:38": 1,
    "16 09:00:30": 1,
    "16 09:00:21": 1,
    "15 19:31:52": 1,
    "15 19:09:12": 1,
    "16 10:36:38": 1,
    "15 23:18:15": 1,
    "15 22:17:22": 1,
    "15 14:34:53": 1,
    "17 06:10:06": 1,
    "16 21:38:34": 1,
    "16 20:55:52": 1,
    "14 21:49:34": 1,
    "14 11:16:58": 1,
    "14 02:06:24": 1,
    "13 13:41:07": 1,
    "13 07:52:51": 1,
    "17 09:20:03": 1,
    "17 08:39:32": 1,
    "16 02:56:25": 1,
    "15 06:52:20": 1,
    "11 05:38:44": 1,
    "16 23:11:09": 1,
    "16 21:22:10": 1,
    "14 12:59:52": 1,
    "17 10:30:57": 1,
    "17 10:27:44": 1,
    "17 10:23:23": 1,
    "16 19:52:45": 1,
    "16 18:31:49": 1,
    "16 14:54:22": 1,
    "16 12:38:16": 1,
    "16 12:33:47": 1,
    "16 11:32:09": 1,
    "15 15:49:24": 1,
    "15 01:24:52": 1,
    "11 17:20:59": 1,
    "16 15:23:37": 1,
    "15 10:35:34": 1,
    "12 01:01:32": 1
  }
}