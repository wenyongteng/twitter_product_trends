"""
äº§å“éªŒè¯æ¨¡å—
ä½¿ç”¨LLMéªŒè¯æå–çš„äº§å“å€™é€‰
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

from utils.llm_helper import LLMHelper
from config.config import PRODUCT_DISCOVERY


class ProductValidator:
    """
    äº§å“éªŒè¯å™¨ï¼ˆåŸºäºLLMï¼‰
    """

    def __init__(self, model='deepseek-v3.1-terminus'):
        self.llm = LLMHelper(model=model)
        self.confidence_threshold = PRODUCT_DISCOVERY['confidence_threshold']

    def validate_candidates(self, candidates, tweets_map, batch_size=50):
        """
        éªŒè¯å€™é€‰äº§å“

        Args:
            candidates: å€™é€‰äº§å“åˆ—è¡¨
            tweets_map: æ¨æ–‡æ˜ å°„ {tweet_id: tweet}
            batch_size: æ‰¹å¤„ç†å¤§å°

        Returns:
            list: éªŒè¯é€šè¿‡çš„äº§å“
        """
        print(f"\nğŸ¤– LLMéªŒè¯äº§å“å€™é€‰...")
        print(f"   - å€™é€‰æ•°é‡: {len(candidates)}")
        print(f"   - æ‰¹å¤„ç†å¤§å°: {batch_size}")

        # æŒ‰æ¨æ–‡IDåˆ†ç»„ï¼ˆåŒä¸€æ¨æ–‡çš„å€™é€‰ä¸€èµ·éªŒè¯ï¼‰
        grouped = self._group_by_tweet(candidates)
        print(f"   - æ¶‰åŠæ¨æ–‡: {len(grouped)}")

        validated = []
        total_tweets = len(grouped)

        for i, (tweet_id, tweet_candidates) in enumerate(grouped.items(), 1):
            try:
                tweet = tweets_map.get(tweet_id, {})
                result = self._validate_tweet_products(tweet, tweet_candidates)

                if result and result.get('is_about_product'):
                    validated.extend(result['products'])

                if i % 10 == 0:
                    print(f"   è¿›åº¦: {i}/{total_tweets} æ¨æ–‡")

            except Exception as e:
                print(f"   âš ï¸ éªŒè¯æ¨æ–‡ {tweet_id} å¤±è´¥: {e}")
                continue

        # è¿‡æ»¤ä½ç½®ä¿¡åº¦
        validated = [
            p for p in validated
            if p.get('confidence', 0) >= self.confidence_threshold
        ]

        print(f"   âœ… éªŒè¯å®Œæˆ: {len(validated)} ä¸ªäº§å“é€šè¿‡")

        return validated

    def _group_by_tweet(self, candidates):
        """æŒ‰æ¨æ–‡IDåˆ†ç»„"""
        grouped = {}
        for candidate in candidates:
            tweet_id = candidate['tweet_id']
            if tweet_id not in grouped:
                grouped[tweet_id] = []
            grouped[tweet_id].append(candidate)
        return grouped

    def _validate_tweet_products(self, tweet, candidates):
        """
        éªŒè¯å•æ¡æ¨æ–‡ä¸­çš„äº§å“å€™é€‰

        Args:
            tweet: æ¨æ–‡æ•°æ®
            candidates: è¯¥æ¨æ–‡çš„å€™é€‰åˆ—è¡¨

        Returns:
            dict: éªŒè¯ç»“æœ
        """
        text = tweet.get('text', '')

        # æ„å»ºprompt
        prompt = self._build_validation_prompt(text, candidates)

        # è°ƒç”¨LLM
        result = self.llm.call_claude_json(prompt)

        # æ·»åŠ åŸå§‹ä¿¡æ¯
        if result.get('is_about_product') and result.get('products'):
            for product in result['products']:
                product['tweet_id'] = tweet.get('id', '')
                product['tweet_text'] = text
                product['author'] = tweet.get('author_id', '')

        return result

    def _build_validation_prompt(self, tweet_text, candidates):
        """
        æ„å»ºéªŒè¯prompt

        Args:
            tweet_text: æ¨æ–‡æ–‡æœ¬
            candidates: å€™é€‰åˆ—è¡¨

        Returns:
            str: prompt
        """
        # æ ¼å¼åŒ–å€™é€‰
        candidate_list = "\n".join([
            f"- {c['product_name']} (ä¿¡å·: {c['signal_word']}, ç±»åˆ«: {c['signal_category']})"
            for c in candidates
        ])

        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªAIäº§å“è¯†åˆ«ä¸“å®¶ã€‚æˆ‘ä»è¿™æ¡æ¨æ–‡ä¸­æ£€æµ‹åˆ°ä¸€äº›å¯èƒ½çš„äº§å“åç§°ï¼Œè¯·å¸®æˆ‘éªŒè¯ã€‚

ã€æ¨æ–‡å†…å®¹ã€‘
"{tweet_text}"

ã€å€™é€‰äº§å“ã€‘
{candidate_list}

ã€ä»»åŠ¡ã€‘
è¯·åˆ†æï¼š
1. è¿™æ¡æ¨æ–‡æ˜¯å¦çœŸçš„åœ¨è®¨è®ºAIäº§å“/æ¨¡å‹/å·¥å…·ï¼Ÿ
2. å¦‚æœæ˜¯ï¼Œæå–å‡ºå‡†ç¡®çš„äº§å“åç§°ï¼ˆå¯èƒ½æœ‰å¤šä¸ªï¼‰
3. åˆ¤æ–­æ¯ä¸ªäº§å“çš„ç±»å‹
4. åˆ¤æ–­æ˜¯å¦æ˜¯æ–°å‘å¸ƒçš„äº§å“

ã€åˆ¤æ–­æ ‡å‡†ã€‘
- âœ… æ˜¯äº§å“: Claude, GPT-4, Midjourney, Cursorï¼ˆå…·ä½“çš„AIäº§å“/æ¨¡å‹/å·¥å…·ï¼‰
- âŒ ä¸æ˜¯äº§å“: AI, ChatGPT(å¤ªé€šç”¨), Google(å…¬å¸å), OpenAI(å…¬å¸å)
- âŒ ä¸æ˜¯äº§å“: äººåã€åœ°åã€é€šç”¨è¯æ±‡

ã€è¿”å›æ ¼å¼ã€‘
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼š

{{
  "is_about_product": true/false,
  "products": [
    {{
      "name": "å‡†ç¡®çš„äº§å“åï¼ˆé¦–å­—æ¯å¤§å†™ï¼‰",
      "type": "model/tool/platform/other",
      "is_new_release": true/false,
      "confidence": 0.0-1.0,
      "reasoning": "ç®€çŸ­çš„åˆ¤æ–­ç†ç”±"
    }}
  ]
}}

æ³¨æ„ï¼š
- å¦‚æœä¸æ˜¯åœ¨è®¨è®ºäº§å“ï¼Œè¿”å› {{"is_about_product": false, "products": []}}
- äº§å“åè¦å‡†ç¡®ï¼Œå»é™¤å¤šä½™è¯æ±‡ï¼ˆå¦‚"the new"ç­‰ï¼‰
- ç½®ä¿¡åº¦è¦è¯šå®ï¼Œä¸ç¡®å®šçš„ç»™ä½åˆ†
- is_new_release: åªæœ‰æ˜ç¡®è¯´"å‘å¸ƒ/released/announced"æ‰æ˜¯true
"""

        return prompt

    def merge_similar_products(self, products):
        """
        åˆå¹¶ç›¸ä¼¼çš„äº§å“åï¼ˆç®€å•ç‰ˆæœ¬ï¼‰

        Args:
            products: äº§å“åˆ—è¡¨

        Returns:
            list: åˆå¹¶åçš„äº§å“
        """
        from difflib import SequenceMatcher

        if len(products) <= 1:
            return products

        # è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ
        n = len(products)
        merged_indices = set()
        final_products = []

        for i in range(n):
            if i in merged_indices:
                continue

            current = products[i]
            similar_group = [current]

            for j in range(i + 1, n):
                if j in merged_indices:
                    continue

                # è®¡ç®—åç§°ç›¸ä¼¼åº¦
                name1 = current['name'].lower()
                name2 = products[j]['name'].lower()

                similarity = SequenceMatcher(None, name1, name2).ratio()

                # åŒ…å«å…³ç³»ä¹Ÿè®¤ä¸ºç›¸ä¼¼
                if name1 in name2 or name2 in name1:
                    similarity = max(similarity, 0.8)

                # ç›¸ä¼¼åº¦é˜ˆå€¼
                if similarity > 0.7:
                    similar_group.append(products[j])
                    merged_indices.add(j)

            # é€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„ä½œä¸ºä»£è¡¨
            representative = max(similar_group, key=lambda x: x.get('confidence', 0))
            final_products.append(representative)

            merged_indices.add(i)

        return final_products


if __name__ == '__main__':
    # æµ‹è¯•
    validator = ProductValidator()

    test_candidates = [
        {
            'product_name': 'GPT-5',
            'tweet_id': 'test_1',
            'signal_word': 'just released',
            'signal_category': 'launch',
        }
    ]

    test_tweets = {
        'test_1': {
            'id': 'test_1',
            'text': 'OpenAI just released GPT-5 and it\'s amazing!',
            'author_id': 'user123',
        }
    }

    result = validator.validate_candidates(test_candidates, test_tweets)
    print("\néªŒè¯ç»“æœ:", json.dumps(result, indent=2, ensure_ascii=False))
